{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01c07d8",
   "metadata": {},
   "source": [
    "# Validacion Cruzada K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d302a3",
   "metadata": {},
   "source": [
    "Es una tecnica robusta para evaluar el rendimiento de un modelo de Machine Learning y evitar problemas como el sobreajuste (*overfitting*). El proceso general de este metodo es el siguiente:\n",
    "\n",
    "1.- **Dividir de los datos**: El conjunto de datos se divide en $K$ subconjuntos aproximadamente del mismo tamano. A estos se les conoce como \"*Fold*\"\n",
    "\n",
    "2.- **Iterar a traves de los Folds**: Se realizan $K$ iteraciones de entrenamiento y prueba. En cada iteracion, unos de los K folds se utiliza como conjunto de prueba y los otros $K-1$ folds como conjunto de entrenamiento. Esto implica que cada observacion se utiliza exactamente una vez como conjunto de prueba y $K-1$ veces como parte del conjunto de entrenamiento.\n",
    "\n",
    "3.- **Evaluar el modelo**: Se obtienen las metricas del modelo para cada iteracion de los folds. \n",
    "\n",
    "4.- **Promediar resultados**: Despues de las $K$ iteraciones, se promedian las metricas de rendimiento (como precision, MSE, R-cuadrado, entre otros) para obtener una estimacion mas confiable del rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5fde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2741b21",
   "metadata": {},
   "source": [
    "## Ventajas y Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95ccd4",
   "metadata": {},
   "source": [
    "- Al utilizar todos los datos tanto para entrenamiento como para prueba, se obtiene una mejor estimacion del rendimiento del modelo.\n",
    "\n",
    "- Al promediar los resultados de las iteraciones, se reduce la varianza asociada con cualquier particion de los datos.\n",
    "\n",
    "- A diferencia de la validacion Hold Out, se utilizan todos los datos disponibles tanto para entrenamiento como para prueba\n",
    "\n",
    "- Su principal desventaja es que requiere entrena el modelo $K$ veces lo que implica un alto costo computacional especialmente para modelos complejos y grandes conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b3172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83fe5df5",
   "metadata": {},
   "source": [
    "## Implementacion Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83cd98e",
   "metadata": {},
   "source": [
    "Vamos a implementar la Validacion Cruzada K-Fold de forma manual para entender paso a paso, en que consiste este metodo. Para iniciar, creamos un conjunto de datos aleatorio a los cuales aplicaremos la validacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28726291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.642032</td>\n",
       "      <td>2.453255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.636410</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>2.368823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.161629</td>\n",
       "      <td>4.663183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>4.227003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>-0.344229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.493796</td>\n",
       "      <td>0.349210</td>\n",
       "      <td>0.522243</td>\n",
       "      <td>3.317536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.522733</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>0.769994</td>\n",
       "      <td>3.732305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.427541</td>\n",
       "      <td>0.897110</td>\n",
       "      <td>0.215821</td>\n",
       "      <td>2.342611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.887086</td>\n",
       "      <td>0.622890</td>\n",
       "      <td>1.309792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.779876</td>\n",
       "      <td>0.085347</td>\n",
       "      <td>-0.402885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1     var_2     var_3         y\n",
       "0   0.374540  0.031429  0.642032  2.453255\n",
       "1   0.950714  0.636410  0.084140  2.368823\n",
       "2   0.731994  0.314356  0.161629  4.663183\n",
       "3   0.598658  0.508571  0.898554  4.227003\n",
       "4   0.156019  0.907566  0.606429 -0.344229\n",
       "..       ...       ...       ...       ...\n",
       "95  0.493796  0.349210  0.522243  3.317536\n",
       "96  0.522733  0.725956  0.769994  3.732305\n",
       "97  0.427541  0.897110  0.215821  2.342611\n",
       "98  0.025419  0.887086  0.622890  1.309792\n",
       "99  0.107891  0.779876  0.085347 -0.402885\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# librerias de manejo de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# semilla aleatoria\n",
    "np.random.seed(42)\n",
    "\n",
    "# 3 Variables predictoras\n",
    "X = pd.DataFrame({\n",
    "    'var_1': np.random.rand(100),\n",
    "    'var_2': np.random.rand(100),\n",
    "    'var_3': np.random.rand(100),\n",
    "})\n",
    "\n",
    "# Variable objetivo\n",
    "y = 3*X['var_1'] + 2*X['var_3'] + np.random.randn(100)\n",
    "\n",
    "# y convertida en Serie\n",
    "df_y = pd.Series(y, name='y')\n",
    "\n",
    "# concatenamos la variable objetivo con las predictoras\n",
    "df = pd.concat([X, df_y], axis=1)\n",
    "\n",
    "# mostrar datos creados\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7515da",
   "metadata": {},
   "source": [
    "Se han creado 100 observaciones con datos aleatorios para 3 variables predictoras y una objetivo. Decidimos que la variable 'y' presente una relacion lineal con las variables var_1 y var_3 para tener certeza sobre los resultados esperados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6c3e4",
   "metadata": {},
   "source": [
    "###  **1.- Dividir los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3337d2",
   "metadata": {},
   "source": [
    "Definimos el numero de folds que popularmente se toma $K=5$ o $K=10$ y calculamos el tamano de cada fold dividiendo el numero total de observaciones entre $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f4e437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numero de folds\n",
    "K = 5\n",
    "# numero total de muestras (100 en este caso)\n",
    "n_muestras = len(X)\n",
    "# tamano de los folds\n",
    "size_fold = n_muestras // K\n",
    "# mostrar tamano de los folds\n",
    "size_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b009f6e",
   "metadata": {},
   "source": [
    "Tenemos 5 folds de 20 observaciones cada uno. Ahora, mezclamos los indices de las observaciones aleatoriamente para asegurar que la division de los folds sea aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ff8308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.520068</td>\n",
       "      <td>0.502679</td>\n",
       "      <td>0.966655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.292145</td>\n",
       "      <td>0.318003</td>\n",
       "      <td>0.093675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.366362</td>\n",
       "      <td>0.110052</td>\n",
       "      <td>0.367716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.045227</td>\n",
       "      <td>0.237638</td>\n",
       "      <td>0.570061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.325183</td>\n",
       "      <td>0.659984</td>\n",
       "      <td>0.035942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.965632</td>\n",
       "      <td>0.942910</td>\n",
       "      <td>0.195243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.606429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.770967</td>\n",
       "      <td>0.339030</td>\n",
       "      <td>0.127061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.212339</td>\n",
       "      <td>0.808120</td>\n",
       "      <td>0.224269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.684233</td>\n",
       "      <td>0.363630</td>\n",
       "      <td>0.645472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1     var_2     var_3\n",
       "47  0.520068  0.502679  0.966655\n",
       "22  0.292145  0.318003  0.093675\n",
       "23  0.366362  0.110052  0.367716\n",
       "58  0.045227  0.237638  0.570061\n",
       "85  0.325183  0.659984  0.035942\n",
       "..       ...       ...       ...\n",
       "34  0.965632  0.942910  0.195243\n",
       "4   0.156019  0.907566  0.606429\n",
       "94  0.770967  0.339030  0.127061\n",
       "13  0.212339  0.808120  0.224269\n",
       "38  0.684233  0.363630  0.645472\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mezcla aleatoria de los indices\n",
    "mix_index = np.random.permutation(n_muestras)\n",
    "# reordenar valores de X con indices mezclados\n",
    "X_mix = X.iloc[mix_index]\n",
    "# reordenar valores de y con indices mezclados\n",
    "y_mix = y.iloc[mix_index]\n",
    "# mostrar Variables predicotras mezcladas\n",
    "X_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8fe40",
   "metadata": {},
   "source": [
    "Una vez mezclada las observaciones, inicializamos las listas que almacenaran las metricas del modelo. En este caso utilizaremos un modelo de Regresion Lineal por lo que las metricas a evaluar son $R^2$ y $MSE$. Debemos crear un par de listas para las metricas del conjunto entrenamiento y otro par para el conjunto de prueba en cada fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff6403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias para usar el modelo y las metricas\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# listas para metricas de entrenamiento\n",
    "train_r2 = []\n",
    "train_mse = []\n",
    "\n",
    "# listas para metricas de prueba\n",
    "test_r2 = []\n",
    "test_mse = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70e79e",
   "metadata": {},
   "source": [
    "### **2 y 3.- Iterar sobre cada fold y entrenar el modelo K veces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb74e544",
   "metadata": {},
   "source": [
    "Con un bucle, iteramos sobre cada fold con el que se entrena el modelo y se calcula las metricas tanto para el conjunto de entrenamiento como de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b7d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    # indice inicial fold actual\n",
    "    ini = k*size_fold\n",
    "    # indice final fold actual\n",
    "    fin = (k+1)*size_fold\n",
    "    \n",
    "    #asignar observaciones al conjunto de prueba\n",
    "    X_test = X_mix.iloc[ini:fin]\n",
    "    y_test = y_mix.iloc[ini:fin]\n",
    "    # asignar las observaciones restantes al conjunto de entrenamiento\n",
    "    X_train = pd.concat([X_mix.iloc[:ini], X_mix.iloc[fin:]])\n",
    "    y_train = pd.concat([y_mix.iloc[:ini], y_mix.iloc[fin:]])\n",
    "    \n",
    "    # instanciar y entrenar el modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predicciones con datos de entrenamiento\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # predicciones con datos de prueba\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # calculo de metricas de entrenamiento\n",
    "    train_r2.append(r2_score(y_train, y_train_pred))\n",
    "    train_mse.append(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    # calculo de metricas de prueba\n",
    "    test_r2.append(r2_score(y_test, y_test_pred))\n",
    "    test_mse.append(mean_squared_error(y_test, y_test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825a19b",
   "metadata": {},
   "source": [
    "### **4.- Promediar resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6a14b",
   "metadata": {},
   "source": [
    "Se promedian las metricas para los conjuntos de entrenamiento y prueba a lo largo de todos los folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebdffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de R-cuadrado para datos de entrenamiento: 0.6082\n",
      "Promedio de R-cuadrado para datos de prueba: 0.5314\n",
      "Promedio de MSE para datos de entrenamiento: 0.9168\n",
      "Promedio de MSE para datos de prueba: 1.0338\n"
     ]
    }
   ],
   "source": [
    "print(f'Promedio de R-cuadrado para datos de entrenamiento: {round(np.mean(train_r2),4)}')\n",
    "print(f'Promedio de R-cuadrado para datos de prueba: {round(np.mean(test_r2),4)}')\n",
    "print(f'Promedio de MSE para datos de entrenamiento: {round(np.mean(train_mse),4)}')\n",
    "print(f'Promedio de MSE para datos de prueba: {round(np.mean(test_mse),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd31069",
   "metadata": {},
   "source": [
    "> La diferencia entre el RÂ² y el MSE en los conjuntos de entrenamiento y prueba sugiere que el modelo puede estar sobreajustado. EstÃ¡ capturando bien la variabilidad en los datos de entrenamiento, pero su capacidad para generalizar a datos nuevos es algo limitada.\n",
    "\n",
    "> El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento y no generaliza bien a nuevos datos. En este caso, el RÂ² es mÃ¡s alto y el MSE es mÃ¡s bajo en el conjunto de entrenamiento en comparaciÃ³n con el conjunto de prueba.\n",
    "\n",
    "> A pesar de estas diferencias, este metodo captura mucho mejor el rendimiento del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f46aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "113b223e",
   "metadata": {},
   "source": [
    "## Implementacion con Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1d3b8",
   "metadata": {},
   "source": [
    "La implementacion de esta tecnica con Scikit Learn nos permite reducir lineas de codigo pero el procedimiento es el mismo. Vamos a trabajar sobre los datos de prueba anteriores: X e y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc95549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.642032</td>\n",
       "      <td>2.453255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.636410</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>2.368823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.161629</td>\n",
       "      <td>4.663183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>4.227003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>-0.344229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.493796</td>\n",
       "      <td>0.349210</td>\n",
       "      <td>0.522243</td>\n",
       "      <td>3.317536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.522733</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>0.769994</td>\n",
       "      <td>3.732305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.427541</td>\n",
       "      <td>0.897110</td>\n",
       "      <td>0.215821</td>\n",
       "      <td>2.342611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.887086</td>\n",
       "      <td>0.622890</td>\n",
       "      <td>1.309792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.779876</td>\n",
       "      <td>0.085347</td>\n",
       "      <td>-0.402885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1     var_2     var_3         y\n",
       "0   0.374540  0.031429  0.642032  2.453255\n",
       "1   0.950714  0.636410  0.084140  2.368823\n",
       "2   0.731994  0.314356  0.161629  4.663183\n",
       "3   0.598658  0.508571  0.898554  4.227003\n",
       "4   0.156019  0.907566  0.606429 -0.344229\n",
       "..       ...       ...       ...       ...\n",
       "95  0.493796  0.349210  0.522243  3.317536\n",
       "96  0.522733  0.725956  0.769994  3.732305\n",
       "97  0.427541  0.897110  0.215821  2.342611\n",
       "98  0.025419  0.887086  0.622890  1.309792\n",
       "99  0.107891  0.779876  0.085347 -0.402885\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe con las variables de X e y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc5f0d",
   "metadata": {},
   "source": [
    "### **1.- Dividir los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce17290",
   "metadata": {},
   "source": [
    "importamos el metodo KFold, lo configuramos con las cantidad de pliegues requeridos, una semilla aleatoria y con mezclado de los datos para asegurar aleatoriedad en la eleccion de los pliegues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07405542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=42, shuffle=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libreria para utilizar KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Configuracion KFold\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "kf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09d72f",
   "metadata": {},
   "source": [
    "Ahora, procedemos a crear el par de listas que almacenaran las metricas obtenidas por el modelo entrenado con los datos de entrenamiento y otro par para las metricas obtenidas al evaluar el modelo con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80b8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas para metricas de entrenamiento\n",
    "train_r2 = []\n",
    "train_mse = []\n",
    "\n",
    "# listas para metricas de prueba\n",
    "test_r2 = []\n",
    "test_mse = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b1b18",
   "metadata": {},
   "source": [
    "### **2 y 3.- Iterar sobre cada fold y entrenar el modelo K veces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5de79f",
   "metadata": {},
   "source": [
    "- Se itera sobre los pliegues (Folds) generados por Kf. \n",
    "\n",
    "- Kf devuelve indices de entrenamiento y prueba para cada pliegue. \n",
    "\n",
    "- Para cada pliegue, se divide los datos de $X$ e $y$ en conjuntos de entrenamiento y prueba usando los indices generados.\n",
    "\n",
    "- Se entrena el modelo y se obtienen las prediccions para luego calcular las metricas del modelo tanto de los datos de entrenamiento como e prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7445664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterar sobre los indices de cada pliegue\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # datos de entrenamiento y prueba para el pliegue actual\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # instanciar y entrenar el modelo\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # predicciones con datos de entrenamiento\n",
    "    y_train_pred = modelo.predict(X_train)\n",
    "    # predicciones con datos de prueba\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # calculo de metricas de entrenamiento\n",
    "    train_r2.append(r2_score(y_train, y_train_pred))\n",
    "    train_mse.append(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    # calculo de metricas de prueba\n",
    "    test_r2.append(r2_score(y_test, y_test_pred))\n",
    "    test_mse.append(mean_squared_error(y_test, y_test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a3fed",
   "metadata": {},
   "source": [
    "### **4.- Promediar resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02215c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de R-cuadrado para datos de entrenamiento: 0.6113\n",
      "Promedio de R-cuadrado para datos de prueba: 0.5357\n",
      "Promedio de MSE para datos de entrenamiento: 0.9131\n",
      "Promedio de MSE para datos de prueba: 1.0662\n"
     ]
    }
   ],
   "source": [
    "print(f'Promedio de R-cuadrado para datos de entrenamiento: {round(np.mean(train_r2),4)}')\n",
    "print(f'Promedio de R-cuadrado para datos de prueba: {round(np.mean(test_r2),4)}')\n",
    "print(f'Promedio de MSE para datos de entrenamiento: {round(np.mean(train_mse),4)}')\n",
    "print(f'Promedio de MSE para datos de prueba: {round(np.mean(test_mse),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acbeae",
   "metadata": {},
   "source": [
    "> Obtenemos los mismo resultados que al aplicarlo de forma manual. KFold de Scikit Learn mezcla los datos y selecciona los indices de cada pliegue, por tanto en este caso, arroja 5 pares de indices (inicial y final) debido a que fueron seleccionados 5 folds.\n",
    "\n",
    "> Al promediar los resultados, se obtiene una estimacion mas robusta y menos sesgada. Ademas, esta tecnica utiliza todos los datos tanto para entrenamiento como para prueba lo que le da ventaja sobre otras tecnicas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
