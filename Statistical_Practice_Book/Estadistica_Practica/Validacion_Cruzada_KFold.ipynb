{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451510f4",
   "metadata": {},
   "source": [
    "# Validacion Cruzada K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b563e",
   "metadata": {},
   "source": [
    "Es una tecnica robusta para evaluar el rendimiento de un modelo de Machine Learning y evitar problemas como el sobreajuste (*overfitting*). El proceso general de este metodo es el siguiente:\n",
    "\n",
    "1.- **Dividir de los datos**: El conjunto de datos se divide en $K$ subconjuntos aproximadamente del mismo tamano. A estos se les conoce como \"*Fold*\"\n",
    "\n",
    "2.- **Iterar a traves de los Folds**: Se realizan $K$ iteraciones de entrenamiento y prueba. En cada iteracion, unos de los K folds se utiliza como conjunto de prueba y los otros $K-1$ folds como conjunto de entrenamiento. Esto implica que cada observacion se utiliza exactamente una vez como conjunto de prueba y $K-1$ veces como parte del conjunto de entrenamiento.\n",
    "\n",
    "3.- **Evaluar el modelo**: Se obtienen las metricas del modelo para cada iteracion de los folds. \n",
    "\n",
    "4.- **Promediar resultados**: Despues de las $K$ iteraciones, se promedian las metricas de rendimiento (como precision, MSE, R-cuadrado, entre otros) para obtener una estimacion mas confiable del rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d43005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "726d17ea",
   "metadata": {},
   "source": [
    "## Ventajas y Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b198959",
   "metadata": {},
   "source": [
    "- Al utilizar todos los datos tanto para entrenamiento como para prueba, se obtiene una mejor estimacion del rendimiento del modelo.\n",
    "\n",
    "- Al promediar los resultados de las iteraciones, se reduce la varianza asociada con cualquier particion de los datos.\n",
    "\n",
    "- A diferencia de la validacion Hold Out, se utilizan todos los datos disponibles tanto para entrenamiento como para prueba\n",
    "\n",
    "- Su principal desventaja es que requiere entrena el modelo $K$ veces lo que implica un alto costo computacional especialmente para modelos complejos y grandes conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16fcf555",
   "metadata": {},
   "source": [
    "## Implementacion Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71cd17",
   "metadata": {},
   "source": [
    "Vamos a implementar la Validacion Cruzada K-Fold de forma manual para entender paso a paso, en que consiste este metodo. Para iniciar, creamos un conjunto de datos aleatorio a los cuales aplicaremos la validacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff015706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.642032</td>\n",
       "      <td>2.453255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.636410</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>2.368823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.161629</td>\n",
       "      <td>4.663183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>4.227003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>-0.344229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.493796</td>\n",
       "      <td>0.349210</td>\n",
       "      <td>0.522243</td>\n",
       "      <td>3.317536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.522733</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>0.769994</td>\n",
       "      <td>3.732305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.427541</td>\n",
       "      <td>0.897110</td>\n",
       "      <td>0.215821</td>\n",
       "      <td>2.342611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.887086</td>\n",
       "      <td>0.622890</td>\n",
       "      <td>1.309792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.779876</td>\n",
       "      <td>0.085347</td>\n",
       "      <td>-0.402885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1     var_2     var_3         y\n",
       "0   0.374540  0.031429  0.642032  2.453255\n",
       "1   0.950714  0.636410  0.084140  2.368823\n",
       "2   0.731994  0.314356  0.161629  4.663183\n",
       "3   0.598658  0.508571  0.898554  4.227003\n",
       "4   0.156019  0.907566  0.606429 -0.344229\n",
       "..       ...       ...       ...       ...\n",
       "95  0.493796  0.349210  0.522243  3.317536\n",
       "96  0.522733  0.725956  0.769994  3.732305\n",
       "97  0.427541  0.897110  0.215821  2.342611\n",
       "98  0.025419  0.887086  0.622890  1.309792\n",
       "99  0.107891  0.779876  0.085347 -0.402885\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# librerias de manejo de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# semilla aleatoria\n",
    "np.random.seed(42)\n",
    "\n",
    "# 3 Variables predictoras\n",
    "X = pd.DataFrame({\n",
    "    'var_1': np.random.rand(100),\n",
    "    'var_2': np.random.rand(100),\n",
    "    'var_3': np.random.rand(100),\n",
    "})\n",
    "\n",
    "# Variable objetivo\n",
    "y = 3*X['var_1'] + 2*X['var_3'] + np.random.randn(100)\n",
    "\n",
    "# y convertida en Serie\n",
    "df_y = pd.Series(y, name='y')\n",
    "\n",
    "# concatenamos la variable objetivo con las predictoras\n",
    "df = pd.concat([X, df_y], axis=1)\n",
    "\n",
    "# mostrar datos creados\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be0a61",
   "metadata": {},
   "source": [
    "Se han creado 100 observaciones con datos aleatorios para 3 variables predictoras y una objetivo. Decidimos que la variable 'y' presente una relacion lineal con las variables var_1 y var_3 para tener certeza sobre los resultados esperados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e1cbb",
   "metadata": {},
   "source": [
    "###  **1.- Dividir los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91103d8c",
   "metadata": {},
   "source": [
    "Definimos el numero de folds que popularmente se toma $K=5$ o $K=10$ y calculamos el tamano de cada fold dividiendo el numero total de observaciones entre $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef9752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numero de folds\n",
    "K = 5\n",
    "# numero total de muestras (100 en este caso)\n",
    "n_muestras = len(X)\n",
    "# tamano de los folds\n",
    "size_fold = n_muestras // K\n",
    "# mostrar tamano de los folds\n",
    "size_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad97d6",
   "metadata": {},
   "source": [
    "Tenemos 5 folds de 20 observaciones cada uno. Ahora, mezclamos los indices de las observaciones aleatoriamente para asegurar que la division de los folds sea aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11cb7e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.093103</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.122038</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.940459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.637557</td>\n",
       "      <td>0.555201</td>\n",
       "      <td>0.542645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.291229</td>\n",
       "      <td>0.539342</td>\n",
       "      <td>0.849223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.887213</td>\n",
       "      <td>0.529651</td>\n",
       "      <td>0.286541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.803672</td>\n",
       "      <td>0.325400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.828738</td>\n",
       "      <td>0.633530</td>\n",
       "      <td>0.140084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.199674</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.973011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.356753</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>0.518330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.779876</td>\n",
       "      <td>0.085347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1     var_2     var_3\n",
       "90  0.119594  0.093103  0.030500\n",
       "40  0.122038  0.962447  0.940459\n",
       "87  0.637557  0.555201  0.542645\n",
       "19  0.291229  0.539342  0.849223\n",
       "88  0.887213  0.529651  0.286541\n",
       "..       ...       ...       ...\n",
       "16  0.304242  0.803672  0.325400\n",
       "62  0.828738  0.633530  0.140084\n",
       "26  0.199674  0.818015  0.973011\n",
       "63  0.356753  0.535775  0.518330\n",
       "99  0.107891  0.779876  0.085347\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mezcla aleatoria de los indices\n",
    "mix_index = np.random.permutation(n_muestras)\n",
    "# reordenar valores de X con indices mezclados\n",
    "X_mix = X.iloc[mix_index]\n",
    "# reordenar valores de y con indices mezclados\n",
    "y_mix = y.iloc[mix_index]\n",
    "# mostrar Variables predicotras mezcladas\n",
    "X_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c192811",
   "metadata": {},
   "source": [
    "Una vez mezclada las observaciones, inicializamos las listas que almacenaran las metricas del modelo. En este caso utilizaremos un modelo de Regresion Lineal por lo que las metricas a evaluar son $R^2$ y $MSE$. Debemos crear un par de listas para las metricas del conjunto entrenamiento y otro par para el conjunto de prueba en cada fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0900e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias para usar el modelo y las metricas\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# listas para metricas de entrenamiento\n",
    "train_r2 = []\n",
    "train_mse = []\n",
    "\n",
    "# listas para metricas de prueba\n",
    "test_r2 = []\n",
    "test_mse = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f913937",
   "metadata": {},
   "source": [
    "### **2 y 3.- Iterar sobre cada fold y entrenar el modelo K veces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150b9ba",
   "metadata": {},
   "source": [
    "Con un bucle, iteramos sobre cada fold con el que se entrena el modelo y se calcula las metricas tanto para el conjunto de entrenamiento como de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e694e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    # indice inicial fold actual\n",
    "    ini = k*size_fold\n",
    "    # indice final fold actual\n",
    "    fin = (k+1)*size_fold\n",
    "    \n",
    "    #asignar observaciones al conjunto de prueba\n",
    "    X_test = X_mix.iloc[ini:fin]\n",
    "    y_test = y_mix.iloc[ini:fin]\n",
    "    # asignar las observaciones restantes al conjunto de entrenamiento\n",
    "    X_train = pd.concat([X_mix.iloc[:ini], X_mix.iloc[fin:]])\n",
    "    y_train = pd.concat([y_mix.iloc[:ini], y_mix.iloc[fin:]])\n",
    "    \n",
    "    # instanciar y entrenar el modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predicciones con datos de entrenamiento\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # predicciones con datos de prueba\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # calculo de metricas de entrenamiento\n",
    "    train_r2.append(r2_score(y_train, y_train_pred))\n",
    "    train_mse.append(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    # calculo de metricas de prueba\n",
    "    test_r2.append(r2_score(y_test, y_test_pred))\n",
    "    test_mse.append(mean_squared_error(y_test, y_test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ecc42",
   "metadata": {},
   "source": [
    "### **4.- Promediar resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8194f",
   "metadata": {},
   "source": [
    "Se promedian las metricas para los conjuntos de entrenamiento y prueba a lo largo de todos los folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a285515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de R-cuadrado para datos de entrenamiento: 0.6075\n",
      "Promedio de R-cuadrado para datos de prueba: 0.5688\n",
      "Promedio de MSE para datos de entrenamiento: 0.9214\n",
      "Promedio de MSE para datos de prueba: 0.9932\n"
     ]
    }
   ],
   "source": [
    "print(f'Promedio de R-cuadrado para datos de entrenamiento: {round(np.mean(train_r2),4)}')\n",
    "print(f'Promedio de R-cuadrado para datos de prueba: {round(np.mean(test_r2),4)}')\n",
    "print(f'Promedio de MSE para datos de entrenamiento: {round(np.mean(train_mse),4)}')\n",
    "print(f'Promedio de MSE para datos de prueba: {round(np.mean(test_mse),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ca04e",
   "metadata": {},
   "source": [
    "> La diferencia entre el R² y el MSE en los conjuntos de entrenamiento y prueba sugiere que el modelo puede estar sobreajustado. Está capturando bien la variabilidad en los datos de entrenamiento, pero su capacidad para generalizar a datos nuevos es algo limitada ($R^2$ de entrenamiento es mayor que $R^2$ de prueba).\n",
    "\n",
    "> El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento y no generaliza bien a nuevos datos. En tu caso, el R² es más alto y el MSE es más bajo en el conjunto de entrenamiento en comparación con el conjunto de prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
