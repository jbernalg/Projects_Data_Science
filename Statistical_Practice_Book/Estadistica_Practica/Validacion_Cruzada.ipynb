{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de567a5b",
   "metadata": {},
   "source": [
    "# Validacion Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97160ca8",
   "metadata": {},
   "source": [
    "Es una tecnica de evaluacion del rendimiento de los modelos de Machine Learning que se utiliza para evaluar como se desempeña un modelo ante un conjunto de datos que no ha visto.\n",
    "\n",
    "La idea principal es dividir los datos en varios subconjuntos, entrenar el modelo en algunos de estos subconjuntos y probarlo en los subconjuntos restantes.\n",
    "\n",
    "En lo que sigue veremos una de las validaciones cruzadas mas importantes: Hold-Out Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7aa8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c3bc511",
   "metadata": {},
   "source": [
    "# **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ae135",
   "metadata": {},
   "source": [
    "Es la tecnica mas comun utilizada para entrenar y probar el modelo. Consiste en dividir los datos en dos partes: uno para entrenamiento y otro para prueba. El proceso general es el siguiente:\n",
    "\n",
    "1.- **Dividir los datos**: Los datos se dividen en dos partes, generalmente una proporcion de 70-80% para entrenamiento y 20-30% para prueba.\n",
    "\n",
    "2.- **Entrenar el modelo**: el modelo se entrena utilizando solo el conjunto de entrenamiento.\n",
    "\n",
    "3.- **Evaluar el modelo**: el modelo entrenado se evalua en el conjunto de prueba para medir su rendimiento.\n",
    "\n",
    "Su facilidad para implementar y entender y su bajo costo computacional hacen de esta tecnica una de las favoritas. \n",
    "\n",
    "Su desventaja es que el rendimiento del modelo puede variar significativamente dependiendo de como se dividen los datos; ademas, no todos los datos se utilizan para entrenar el modelo lo cual es un problema para conjuntos de datos pequeños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64cf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cd4453c",
   "metadata": {},
   "source": [
    "## Implementacion de Hold-Out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa10b81",
   "metadata": {},
   "source": [
    "Vamos a crear un conjunto de datos simple para aplicar la hold-out validation manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ea919b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9180d1",
   "metadata": {},
   "source": [
    "Generamos datos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0185c7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.642032</td>\n",
       "      <td>0.051682</td>\n",
       "      <td>0.103124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.636410</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>0.531355</td>\n",
       "      <td>0.902553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.161629</td>\n",
       "      <td>0.540635</td>\n",
       "      <td>0.505252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.637430</td>\n",
       "      <td>0.826457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.726091</td>\n",
       "      <td>0.320050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.493796</td>\n",
       "      <td>0.349210</td>\n",
       "      <td>0.522243</td>\n",
       "      <td>0.930757</td>\n",
       "      <td>0.353352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.522733</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>0.769994</td>\n",
       "      <td>0.858413</td>\n",
       "      <td>0.583656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.427541</td>\n",
       "      <td>0.897110</td>\n",
       "      <td>0.215821</td>\n",
       "      <td>0.428994</td>\n",
       "      <td>0.077735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.887086</td>\n",
       "      <td>0.622890</td>\n",
       "      <td>0.750871</td>\n",
       "      <td>0.974395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.779876</td>\n",
       "      <td>0.085347</td>\n",
       "      <td>0.754543</td>\n",
       "      <td>0.986211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1     var_2     var_3     var_4     var_5\n",
       "0   0.374540  0.031429  0.642032  0.051682  0.103124\n",
       "1   0.950714  0.636410  0.084140  0.531355  0.902553\n",
       "2   0.731994  0.314356  0.161629  0.540635  0.505252\n",
       "3   0.598658  0.508571  0.898554  0.637430  0.826457\n",
       "4   0.156019  0.907566  0.606429  0.726091  0.320050\n",
       "..       ...       ...       ...       ...       ...\n",
       "95  0.493796  0.349210  0.522243  0.930757  0.353352\n",
       "96  0.522733  0.725956  0.769994  0.858413  0.583656\n",
       "97  0.427541  0.897110  0.215821  0.428994  0.077735\n",
       "98  0.025419  0.887086  0.622890  0.750871  0.974395\n",
       "99  0.107891  0.779876  0.085347  0.754543  0.986211\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# semilla\n",
    "np.random.seed(42)\n",
    "\n",
    "# 5 variables predictoras\n",
    "X = pd.DataFrame({\n",
    "    'var_1': np.random.rand(100),\n",
    "    'var_2': np.random.rand(100),\n",
    "    'var_3': np.random.rand(100),\n",
    "    'var_4': np.random.rand(100),\n",
    "    'var_5': np.random.rand(100),\n",
    "})\n",
    "\n",
    "# variable objetivo\n",
    "# relacionada con algunas variables predictoras de manera lineal\n",
    "y = 3*X['var_1'] + 2*X['var_2'] + X['var_3'] + np.random.rand(100)\n",
    "\n",
    "# mostrar variables predictoras\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3554e",
   "metadata": {},
   "source": [
    "La variable objetivo 'y' esta relacionada de manera lineal con las variables var_1, var_2 y var_3. De esta manera podemos tener certeza sobre los resultados esperados. Ahora, implementamos el Hold-Out Validation de forma manual para entender todo el proceso a detalle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c987fff",
   "metadata": {},
   "source": [
    "### **1.- Dividir los datos**\n",
    "Dividimos los datos en conjunto de entrenamiento y de prueba. Para datos de entrenamiento le asignamos una proporcion del 80% y para datos de prueba, el 20% restante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5ce894ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proporcion de datos de entrenamiento\n",
    "ratio_train = 0.8\n",
    "# canticad de datos de entrenamiento\n",
    "tam_train = int(len(X)*ratio_train)\n",
    "# mostrar cantidad\n",
    "tam_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04623f",
   "metadata": {},
   "source": [
    "Mezclamos los indices de las observaciones para asegurar que los datos de entrenamiento y de prueba se seleccionen aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85cc235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 64, 93, 85, 30, 76, 73, 15, 23, 40, 10, 74, 29, 54,  5, 90, 31,\n",
       "       87, 18, 89, 78, 57, 82, 83, 66, 96, 28, 61, 49, 52, 71,  8, 59, 56,\n",
       "        3, 39, 19, 12, 43, 86, 65, 94, 53, 16, 38,  9, 67, 36, 24, 14, 34,\n",
       "       37, 17, 84, 63, 42, 88, 22, 70,  2,  6, 50, 92, 58, 68, 75,  1, 27,\n",
       "       13, 79, 80, 51,  7, 97, 35, 98, 95, 47, 62, 55, 46, 25, 72, 26, 44,\n",
       "       77, 48, 33, 45, 11, 99,  0, 69, 20, 21, 60, 41, 91, 81,  4])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genera una permutacion aleatoria de los indices de las observaciones\n",
    "mez_indices = np.random.permutation(len(X))\n",
    "mez_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98270e52",
   "metadata": {},
   "source": [
    "Una vez mezclado, seleccionamos los indices para el conjunto de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7646658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32 64 93 85 30 76 73 15 23 40 10 74 29 54  5 90 31 87 18 89 78 57 82 83\n",
      " 66 96 28 61 49 52 71  8 59 56  3 39 19 12 43 86 65 94 53 16 38  9 67 36\n",
      " 24 14 34 37 17 84 63 42 88 22 70  2  6 50 92 58 68 75  1 27 13 79 80 51\n",
      "  7 97 35 98 95 47 62 55]\n",
      "[46 25 72 26 44 77 48 33 45 11 99  0 69 20 21 60 41 91 81  4]\n"
     ]
    }
   ],
   "source": [
    "# indices del conjunto de entrenamiento\n",
    "train_indices = mez_indices[:tam_train]\n",
    "# indices del conjunto de prueba\n",
    "test_indices = mez_indices[tam_train:]\n",
    "# mostrar indices de entrenamiento\n",
    "print(train_indices)\n",
    "# mostrar indices de prueba\n",
    "print(test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add41eb9",
   "metadata": {},
   "source": [
    "Ya obtenido los indices, seleccionamos las observaciones correspondiente a cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "da365792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5) (80,)\n",
      "(20, 5) (20,)\n"
     ]
    }
   ],
   "source": [
    "# variables predictoras de entrenamiento y prueba\n",
    "X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "# variable objetivo de entrenamiento y prueba\n",
    "y_train, y_test = y.iloc[train_indices], y.loc[test_indices]\n",
    "# mostrar dimensiones de datos de entrenamiento\n",
    "print(X_train.shape, y_train.shape)\n",
    "# mostrar dimensiones de datos de prueba\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7972b32",
   "metadata": {},
   "source": [
    "### **2.-  Entrenar el modelo**\n",
    "Creamos un modelo de regresion lineal, debido a la relacion lineal entre las variables predictoras y la variable objetivo, y lo entrenamo con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1367e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creacion del modelo\n",
    "model = LinearRegression()\n",
    "# entrenamiento del modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2a69b",
   "metadata": {},
   "source": [
    "### **3.- Evaluar el modelo**\n",
    "Para evaluarlo, obtenemos las predicciones del modelo con datos de entrenamiento y de prueba y a partir de ello, calculamos sus respectivas metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a15821e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 en datos de entrenamiento: 0.9327\n",
      "MSE en datos de entrenamiento: 0.0842\n",
      "R^2 en datos de prueba: 0.937\n",
      "MSE en datos de prueba: 0.047\n"
     ]
    }
   ],
   "source": [
    "# predicciones con datos de entrenamiento\n",
    "y_train_pred = model.predict(X_train)\n",
    "# predicciones con datos de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "#----------- metricas para datos de entrenamiento\n",
    "# R cuadrado: pasamos como parametro\n",
    "# las predicciones (y_train_pred) y los valores de entrenamiento reales (y_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "# MSE\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "#----------- metricas para datos de prueba\n",
    "# R cuadrado: pasamos como parametro\n",
    "# las predicciones (y_test_pred) y los valores de prueba reales (y_train)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "# MSE\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# mostrar resultados\n",
    "print(f'R^2 en datos de entrenamiento: {round(r2_train,4)}')\n",
    "print(f'MSE en datos de entrenamiento: {round(mse_train,4)}')\n",
    "print(f'R^2 en datos de prueba: {round(r2_test,4)}')\n",
    "print(f'MSE en datos de prueba: {round(mse_test,4)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca0e132",
   "metadata": {},
   "source": [
    "> De esta manera vemos como se desempeña el modelo en el entrenamiento y en presencia de nuevo datos. Las metricas muestran que los valores de R cuadrado son muy similares en ambos caso lo que implica una buena generalizacion del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d75a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25141b5f",
   "metadata": {},
   "source": [
    "## Implementacion de Hold-Out Validation con Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13042000",
   "metadata": {},
   "source": [
    "Podemos reducir el paso 1 a unas pocas lineas de codigo mediante la libreria Scikit Learn tal como sigue:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039893ce",
   "metadata": {},
   "source": [
    "### **1.- Dividir los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da78b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5) (80,)\n",
      "(20, 5) (20,)\n"
     ]
    }
   ],
   "source": [
    "# libreria para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# datos de entrenamiento y prueba\n",
    "# test_size: proporcion de datos de prueba\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# mostrar dimensiones de datos de entrenamiento\n",
    "print(X_train_2.shape, y_train_2.shape)\n",
    "# mostrar dimensiones de datos de prueba\n",
    "print(X_test_2.shape, y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc1423",
   "metadata": {},
   "source": [
    "Vemos que el metodo *train_test_split* divide los datos en la misma proporcion que la implementacion manual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946f64e",
   "metadata": {},
   "source": [
    "### **2.-  Entrenar el modelo**\n",
    "Creamos un modelo de regresion lineal, debido a la relacion lineal entre las variables predictoras y la variable objetivo, y lo entrenamo con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "393467eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creacion del modelo\n",
    "model2 = LinearRegression()\n",
    "# entrenamiento del modelo con los datos de entrenamiento\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25d0e6",
   "metadata": {},
   "source": [
    "### **3.- Evaluar el modelo**\n",
    "Para evaluarlo, obtenemos las predicciones del modelo con datos de entrenamiento y de prueba y a partir de ello, calculamos sus respectivas metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "30f99981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 en datos de entrenamiento: 0.9362\n",
      "MSE en datos de entrenamiento: 0.0789\n",
      "R^2 en datos de prueba: 0.9148\n",
      "MSE en datos de prueba: 0.0682\n"
     ]
    }
   ],
   "source": [
    "# predicciones con datos de entrenamiento\n",
    "y_train_pred = model2.predict(X_train_2)\n",
    "# predicciones con datos de prueba\n",
    "y_test_pred = model2.predict(X_test_2)\n",
    "\n",
    "#----------- metricas para datos de entrenamiento\n",
    "# R cuadrado: pasamos como parametro\n",
    "# las predicciones (y_train_pred) y los valores de entrenamiento reales (y_train_2)\n",
    "r2_train = r2_score(y_train_2, y_train_pred)\n",
    "# MSE\n",
    "mse_train = mean_squared_error(y_train_2, y_train_pred)\n",
    "\n",
    "#----------- metricas para datos de prueba\n",
    "# R cuadrado: pasamos como parametro\n",
    "# las predicciones (y_test_pred) y los valores de prueba reales (y_test_2)\n",
    "r2_test = r2_score(y_test_2, y_test_pred)\n",
    "# MSE\n",
    "mse_test = mean_squared_error(y_test_2, y_test_pred)\n",
    "\n",
    "# mostrar resultados\n",
    "print(f'R^2 en datos de entrenamiento: {round(r2_train,4)}')\n",
    "print(f'MSE en datos de entrenamiento: {round(mse_train,4)}')\n",
    "print(f'R^2 en datos de prueba: {round(r2_test,4)}')\n",
    "print(f'MSE en datos de prueba: {round(mse_test,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb50ab",
   "metadata": {},
   "source": [
    "> Las metricas obtenidas en este caso son muy similares a las obtenidas en la implementacion manual. La ligera diferencia en los resultados se debe a la aleatoriedad en ambos metodos. De esta forma evaluamos el desempeno del modelo con menos lineas de codigo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
