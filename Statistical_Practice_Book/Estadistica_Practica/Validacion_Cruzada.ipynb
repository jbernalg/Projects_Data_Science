{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de567a5b",
   "metadata": {},
   "source": [
    "# Validacion Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97160ca8",
   "metadata": {},
   "source": [
    "Es una tecnica de evaluacion del rendimiento de los modelos de Machine Learning que se utiliza para evaluar como se desempeña un modelo ante un conjunto de datos que no ha visto.\n",
    "\n",
    "La idea principal es dividir los datos en varios subconjuntos, entrenar el modelo en algunos de estos subconjuntos y probarlo en los subconjuntos restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7aa8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f2da460",
   "metadata": {},
   "source": [
    "## Tipos de Validacion Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33757f2d",
   "metadata": {},
   "source": [
    "Existen diferentes tipos de validacion cruzada que puede aplicarse a cualquier modelo de Machine Learning para evaluarlo. Entre los mas comunes tenemos:\n",
    "\n",
    "1.- Validacion de Retencion Simple (Hold-Out Validation)\n",
    "\n",
    "2.- Validacion Cruzada (Cross-Validation)\n",
    "\n",
    "3.- Validacion Cruzada K-Fold\n",
    "\n",
    "4.- Validacion Cruzada Estratificada (Stratified K-Fold Cross-Validation)\n",
    "\n",
    "5.- Validacion Cruzada Leave-One-Out (LOOCV)\n",
    "\n",
    "6.- Validacion Cruzada Leave-P-Out (LPOCV)\n",
    "\n",
    "7.- Bootstrap\n",
    "\n",
    "8.- Validacion Cruzada de Grupos.\n",
    "\n",
    "En lo que sigue, vamos a desarrollar algunas de estas tecnica para entender su implementacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e07d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c3bc511",
   "metadata": {},
   "source": [
    "# 1.- Hold-Out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ae135",
   "metadata": {},
   "source": [
    "Es la tecnica mas comun utilizada para entrenar y probar el modelo. Consiste en dividir los datos en dos partes: uno para entrenamiento y otro para prueba. El proceso general es el siguiente:\n",
    "\n",
    "1.- **Dividir los datos**: Los datos se dividen en dos partes, generalmente una proporcion de 70-80% para entrenamiento y 20-30% para prueba.\n",
    "\n",
    "2.- **Entrenar el modelo**: el modelo se entrena utilizando solo el conjunto de entrenamiento.\n",
    "\n",
    "3.- **Evaluar el modelo**: el modelo entrenado se evalua en el conjunto de prueba para medir su rendimiento.\n",
    "\n",
    "Su facilidad para implementar y entender y su bajo costo computacional hacen de esta tecnica una de las favoritas. \n",
    "\n",
    "Su desventaja es que el rendimiento del modelo puede variar significativamente dependiendo de como se dividen los datos; ademas, no todos los datos se utilizan para entrenar el modelo lo cual es un problema para conjuntos de datos pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4453c",
   "metadata": {},
   "source": [
    "## Implementacion de Hold-Out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa10b81",
   "metadata": {},
   "source": [
    "Vamos a crear un conjunto de datos simple para aplicar la hold-out validation manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea919b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9180d1",
   "metadata": {},
   "source": [
    "Generamos datos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0185c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semilla\n",
    "np.random.seed(42)\n",
    "\n",
    "# 5 variables predictoras\n",
    "X = pd.DataFrame({\n",
    "    'var_1': np.random.rand(100),\n",
    "    'var_2': np.random.rand(100),\n",
    "    'var_3': np.random.rand(100),\n",
    "    'var_4': np.random.rand(100),\n",
    "    'var_5': np.random.rand(100),\n",
    "})\n",
    "\n",
    "# variable objetivo\n",
    "# relacionada con algunas variables predictoras de manera lineal\n",
    "y = 3*X['var_1'] + 2*X['var_2'] + X['var_3'] + np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3554e",
   "metadata": {},
   "source": [
    "La variable objetivo 'y' esta relacionada de manera lineal con las variables var_1, var_2 y var_3. De esta manera podemos tener certeza sobre los resultados esperados. Ahora realizamos el proceso de Hold-Out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c987fff",
   "metadata": {},
   "source": [
    "### **1.- Dividir los datos**\n",
    "Dividimos los datos en conjunto de entrenamiento y de prueba. Para datos de entrenamiento le asignamos una proporcion del 80% y para datos de prueba, un 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce894ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proporcion de datos de entrenamiento\n",
    "ratio_train = 0.8\n",
    "# tamaño de los datos de entrenamiento\n",
    "tam_train = int(len(X)*ratio_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04623f",
   "metadata": {},
   "source": [
    "Mezclamos los indices de las observaciones aleatoriamente para asegurar una distribucion aleatoria de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cc235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genera una permutacion aleatoria de los indices de las filas del df X\n",
    "mez_indices = np.random.permutation(len(X))\n",
    "\n",
    "# seleccion de indices mezclados del conjunto de entrenamiento\n",
    "train_indices = mez_indices[:tam_train]\n",
    "# seleccion de indices mezclados del conjunto de prueba\n",
    "test_indices = mez_indices[tam_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add41eb9",
   "metadata": {},
   "source": [
    "Asignamos los valores de las variables predictoras previamente seleccionadas por los indices al conjunto de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da365792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables predictoras de entrenamiento y prueba\n",
    "X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "# variable objetivo de entrenamiento y prueba\n",
    "y_train, y_test = y.iloc[train_indices], y.loc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7972b32",
   "metadata": {},
   "source": [
    "### **2.-  Entrenar el modelo**\n",
    "Creamos un modelo de regresion lineal, debido a la relacion lineal entre las variables predictoras y la variable objetivo, y los entrenamos con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1367e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creacion del modelo\n",
    "model = LinearRegression()\n",
    "# entrenamiento del modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2a69b",
   "metadata": {},
   "source": [
    "### **3.- Evaluar el modelo**\n",
    "Para evaluarlo, obtenemos las predicciones con los datos de entrenamiento y de prueba y calculamos las metricas del modelo para comparar su desempeño con los datos de entrenamiento y con datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15821e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 en datos de entrenamiento: 0.9327\n",
      "MSE en datos de entrenamiento: 0.0842\n",
      "R^2 en datos de prueba: 0.937\n",
      "MSE en datos de prueba: 0.047\n"
     ]
    }
   ],
   "source": [
    "# predicciones con datos de entrenamiento\n",
    "y_train_pred = model.predict(X_train)\n",
    "# predicciones en el conjunto de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# R cuadrado para datos de entrenamiento\n",
    "# pasamos las predicciones (y_train_pred) y los valores de entrenamiento reales (y_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "# MSE para datos de entrenamiento\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# R cuadrado para datos de prueba\n",
    "# pasamos las predicciones (y_test_pred) y los valores de prueba reales (y_train)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "# MSE para datos de prueba\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# mostrar resultados\n",
    "print(f'R^2 en datos de entrenamiento: {round(r2_train,4)}')\n",
    "print(f'MSE en datos de entrenamiento: {round(mse_train,4)}')\n",
    "print(f'R^2 en datos de prueba: {round(r2_test,4)}')\n",
    "print(f'MSE en datos de prueba: {round(mse_test,4)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca0e132",
   "metadata": {},
   "source": [
    "De esta manera vemos como se desempeña el modelo en el entrenamiento y en presencia de nuevo datos. Las metricas muestran que los valores de R cuadrado son muy similares en ambos caso lo que implica una buena generalizacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d75a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78b860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ab18e0",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7cfed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204582c",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490d1634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cancerdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5517564b",
   "metadata": {},
   "source": [
    "### Seleccion de variables predictoras y objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02b454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos las variables en predictoras y objetivo\n",
    "\n",
    "# variables predictoras\n",
    "X = df.iloc[:,2:]\n",
    "\n",
    "# variable objetivo\n",
    "y = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eba7f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf76af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    M\n",
       "2    M\n",
       "3    M\n",
       "4    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18eb339",
   "metadata": {},
   "source": [
    "### Distribucion de la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43ab9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08490d5f",
   "metadata": {},
   "source": [
    "Vemos que hay muchas representaciones de ambas clases (Benigno y Maligno) lo cual es de suma importancia para un problemas de clasificacion ya que se podria entrenar un modelo de clasificacion de forma correcta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c3364",
   "metadata": {},
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d90b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar arbol de decision\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# importar libreria para dividir los datos\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ab6901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005847953216374"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# creacion del modelo\n",
    "modelo = DecisionTreeClassifier()\n",
    "\n",
    "# entrenamiento del modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# score del modelo\n",
    "result = modelo.score(X_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267c5c0",
   "metadata": {},
   "source": [
    "### Validacion cruzada k-Fold con Arbol de Decision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30f0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos validacion k-fold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7f124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear modelo\n",
    "modelo = DecisionTreeClassifier()\n",
    "\n",
    "# numeros de muestras deseado. (habitualmente son 10)\n",
    "kfold_validacion = KFold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c90ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9122807 , 0.9122807 , 0.89473684, 0.94736842, 0.89473684,\n",
       "       0.98245614, 0.9122807 , 0.96491228, 0.98245614, 0.92857143])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importamos el score de la validacion cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# score de la validacicon cruzada para el modelo de arbol de decision\n",
    "resultados = cross_val_score(modelo, X, y, cv=kfold_validacion)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45cfae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332080200501253"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtenemos el promedio de los resultados\n",
    "resultados.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d93334",
   "metadata": {},
   "source": [
    "### Valiacion cruzada k-Fold con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d828f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos el modelo de bosque aleatorio\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "792a55b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9122807 , 0.9122807 , 0.89473684, 0.98245614, 0.96491228,\n",
       "       0.98245614, 0.96491228, 0.96491228, 0.98245614, 1.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crear modelo \n",
    "modelo_random_tree = RandomForestClassifier()\n",
    "\n",
    "# numeros de muestras deseado. (habitualmente son 10)\n",
    "kfold_validacion = KFold(10)\n",
    "\n",
    "# score de la validacion cruzada para un modelo de bosque aleatorio\n",
    "resultados_forest = cross_val_score(modelo_random_tree, X, y, cv=kfold_validacion)\n",
    "resultados_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf1cb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtenemos el promedio de los resultados\n",
    "resultados_forest.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca4e7b",
   "metadata": {},
   "source": [
    "Vemos que al utilizar un modelo de random forest tenemos mejores resultados que usando arbol de decision.\n",
    "\n",
    "La validación cruzada es muy potente cuando usamos hiperparámetros en nuestros modelos, ya que aumenta la precisión considerablemente. Sin embargo es buena práctica balancear los datos, ya que en la vida real pasa siempre que tenemos una clase mayoritaria. La evalución con una matriz de decisión es sumamente importante para detetectar falsos positivos y faltos negativos en nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86847551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
