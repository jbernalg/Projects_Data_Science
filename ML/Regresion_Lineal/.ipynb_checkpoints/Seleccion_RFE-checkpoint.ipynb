{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72bd7aa",
   "metadata": {},
   "source": [
    "# Eliminacion Recursiva de Features (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddd4da",
   "metadata": {},
   "source": [
    "Es una tecnica utilizada para seleccionar las caracteristicas mas importantes de un conjunto de datos. Su objetivo es eliminar las caracteristicas menos relevantes, mejorando asi el rendimiento del modelo y reduciendo su complejidad.\n",
    "\n",
    "Generalmente, RFE se aplica a modelos que pueden proporcionar alguna medida de la importancia de las caracteristicas como los modelos lineales o arboles de decision. Entre los modelos donde se puede aplicar tenemos:\n",
    "\n",
    "- Regresion Lineal\n",
    "- Regresion Logistica\n",
    "- Arboles de decision\n",
    "- Bosques aleatorios\n",
    "- Maquina de vectores de soporte\n",
    "- Entre otros..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95387ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238dff99",
   "metadata": {},
   "source": [
    "## Como funciona RFE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cfec8",
   "metadata": {},
   "source": [
    "   1. **Entrenamiento inicial**: Entrena un modelo utilizando todas las caracteristicas (Variables predictoras)\n",
    "    \n",
    "    \n",
    "   2. **Evaluacion de Importancia**: Evalua la importancia de cada caracteristica. Esta importancia se puede medir de diferentes maneras dependiendo del modelo utilizado (coeficientes de la regresion lineal)\n",
    "   \n",
    "    \n",
    "   3. **Eliminacion de Caracteristicas**: Elimina las caracteristicas menos importantes para el modelo\n",
    "   \n",
    "   \n",
    "   4. **Repeticion de pasos**: Repite los pasos de 1 a 3 hasta alcanzar un numero predefinido de caracteristicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95297d6",
   "metadata": {},
   "source": [
    "## Aplicacion de RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e88c8",
   "metadata": {},
   "source": [
    "Vamos a crear un conjunto de datos de prueba de 6 variables, incluyendo la variable objetivo y vamos a usar RFE para seleccionar las 3 mas importantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "83085d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos de prueba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 5 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dac478",
   "metadata": {},
   "source": [
    "Para probar el metodo RFE, asociamos linealmente la variable objetivo con 3 de las 5 caracteristicas: feature 1, 2 y 5. Esto nos asegura que el modelo solo va a estar influenciado por estas tres caracteristicas lo cual debe verse reflejado al aplicar RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7b3a8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable objetivo\n",
    "y = 3*X['feature_2'] + 2*X['feature_5'] + X['feature_1'] + np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e8de9",
   "metadata": {},
   "source": [
    "Ahora, juntamos los datos en un Dataframe para mejorar la visualizacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48a8c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.401260</td>\n",
       "      <td>3.695163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>3.756831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.735194</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.333145</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>3.532546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>6.072647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.407241</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>3.242399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5    target\n",
       "0   0.548814   0.677817   0.311796   0.906555   0.401260  3.695163\n",
       "1   0.715189   0.270008   0.696343   0.774047   0.929291  3.756831\n",
       "2   0.602763   0.735194   0.377752   0.333145   0.099615  3.532546\n",
       "3   0.544883   0.962189   0.179604   0.081101   0.945302  6.072647\n",
       "4   0.423655   0.248753   0.024679   0.407241   0.869489  3.242399"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b57aba",
   "metadata": {},
   "source": [
    "### 1.- Entrenamiento inicial\n",
    "Entrenamos el modelo de regresion lineal con todas las caracteristicas y calculamos la importancia de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c6eb2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para usar la regresion lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# funcion para entrena el modelo\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    return model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "34639d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo\n",
    "modelo = train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0feb3b",
   "metadata": {},
   "source": [
    "### 2.- Evaluacion de importancia\n",
    "Para el caso de la regresion, debemos obtener los coeficientes de cada caracteristicas una vez entrenado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97588cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para obtener los coeficientes de cada caracteristica\n",
    "def evaluate_model(model):\n",
    "    coeficientes = model.coef_\n",
    "    return coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "46c29a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0169788 , 2.96313024, 0.01281724, 0.04742558, 1.94336239])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coeficiente de las caracteristicas\n",
    "coefi = evaluate_model(modelo)\n",
    "coefi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b02cb",
   "metadata": {},
   "source": [
    "### 3.- Eliminacion de caracteristicas\n",
    "Identificamos la caracteristica con el coeficiente mas pequeño (el valor absoluto) y la eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6c314b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que determina la caracteristica con menor valor de coeficiente y la elimina\n",
    "def remove_feature(X, coeficientes):\n",
    "    # indice del coficiente mas pequeño\n",
    "    min_indice = np.argmin(np.abs(coeficientes))\n",
    "    # nombre de la caracteristica correspondiente al indice anterior\n",
    "    feature_remove = X.columns[min_indice]\n",
    "    # eliminar caracteristica\n",
    "    X = X.drop(columns=[feature_remove])\n",
    "    # retornar matriz de caracteristica y nombre de la caracteristica eliminada\n",
    "    return X, feature_remove\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d2c34",
   "metadata": {},
   "source": [
    "### 4.- Repetir hasta obtener el numero deseado de caracteristicas\n",
    "\n",
    "Inicialmente dijimos que vamos a obtener las 3 caracteristicas mas importantes. Entonces, repetimos el proceso del 1 al 3 hasta obtener las tres caracteristicas. Para automatizar el proceso, procedemos como sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6dd63987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas seleccionadas Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# numero de features a seleccionar\n",
    "n_features = 3\n",
    "\n",
    "# ejecutar proceso hasta llegar a 3 caracteristicas\n",
    "while X.shape[1] > n_features:\n",
    "    modelo = train_model(X,y)\n",
    "    coefi = evaluate_model(modelo)\n",
    "    X, feature_remove = remove_feature(X, coefi)\n",
    "    \n",
    "# mostrar las 3 caracteristicas mas importantes\n",
    "print('Caracteristicas seleccionadas', X.columns)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbad9cc",
   "metadata": {},
   "source": [
    "Los resultados confirman que los features 1, 2 y 5 son los que realmente influyen sobre el modelo de regresion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bf5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21154913",
   "metadata": {},
   "source": [
    "## Aplicacion de RFE con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fca50a",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar la libreria Scikit Learn para aplicar este metodo y simplificar el proceso de eliminacion recursiva. Trabajaremos sobre los mismos datos de prueba del ejemplo anterior para comparar los resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6017ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.drop(columns=['target'])\n",
    "# variable objetivo\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b1364",
   "metadata": {},
   "source": [
    "Aplicamos RFE con la libreria sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6010769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libreria para aplicar RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# crear modelo de regresion\n",
    "modelo_2 = LinearRegression()\n",
    "\n",
    "# Crear el objeto RFE y especificar el numero de caracteristicas deseadas\n",
    "rfe = RFE(estimator=modelo_2, n_features_to_select=3)\n",
    "\n",
    "# ajustar RFE a los datos\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# obtener las caracteristicas seleccionadas por RFE\n",
    "features_select = X.columns[rfe.support_]\n",
    "\n",
    "# mostrar nombre\n",
    "features_select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74def8",
   "metadata": {},
   "source": [
    "De esta forma, obtenemos los features mas importantes para el modelo de regresion, que en este caso son los features 1, 2 y 5, coincidiendo con los resultados del ejemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd8834c",
   "metadata": {},
   "source": [
    "# Eliminacion Recursiva de Features con Validacion Cruzada (RFECV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85377f1f",
   "metadata": {},
   "source": [
    "Es una tecnica de seleccion de caracteristicas que mejora la metodologia RFE al incoporar la validacion cruzada para seleccionar automaticamente el numero optimo de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8514ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491bfde4",
   "metadata": {},
   "source": [
    "## Como funciona RFECV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b1e94",
   "metadata": {},
   "source": [
    "1. **Entrenamiento del modelo**: Similar a RFE, entrena el modelo usando todas las caracteristicas\n",
    "\n",
    "\n",
    "2. **Validacion Cruzada**: Utiliza la validacion cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.\n",
    "\n",
    "\n",
    "3. **Eliminacion de caracteristicas**: Elimina la caracteristica menos importante y evalua el modelo usando validacion cruzada.\n",
    "\n",
    "\n",
    "4. **Repeticion de pasos**: Repite los pasos 1 hasta 3 hasta que se encuentre el conjunto optimo de caracteristicas que maximiza el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde949ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4488437a",
   "metadata": {},
   "source": [
    "## Aplicacion de RFECV con Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b952a",
   "metadata": {},
   "source": [
    "Vamos a utilizar un conjunto de datos de prueba de 11 caracteristicas incluyendo la variable objetivo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71998070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 10 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100),\n",
    "    'feature_6': np.random.rand(100),\n",
    "    'feature_7': np.random.rand(100),\n",
    "    'feature_8': np.random.rand(100),\n",
    "    'feature_9': np.random.rand(100),\n",
    "    'feature_10': np.random.rand(100)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6d6c6",
   "metadata": {},
   "source": [
    "Relacionamos la variable objetivo con 4 caracteristicas: feature 1, 2, 5 y 7. Esto asegura que de las 10 caracteristicas, solo 4 influencian el modelo y por tanto, al aplicar RFECV, nos debe arrojar dichas caracteristicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "16f2742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.008168\n",
       "1    3.501436\n",
       "2    3.946276\n",
       "3    6.034817\n",
       "4    3.321619\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable objetivo\n",
    "y = (\n",
    "    3*X['feature_2'] + \n",
    "    2*X['feature_5'] + \n",
    "    X['feature_1'] + \n",
    "    X['feature_7']*X['feature_7'] +\n",
    "    np.random.rand(100)\n",
    ")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54280bb",
   "metadata": {},
   "source": [
    "Juntamos los datos en un Dataframe para visualizarlos mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "df799ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.401260</td>\n",
       "      <td>0.310381</td>\n",
       "      <td>0.174658</td>\n",
       "      <td>0.373216</td>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.810839</td>\n",
       "      <td>4.008168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.373035</td>\n",
       "      <td>0.327988</td>\n",
       "      <td>0.222864</td>\n",
       "      <td>0.639705</td>\n",
       "      <td>0.348192</td>\n",
       "      <td>3.501436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.735194</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.333145</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>0.524970</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.408303</td>\n",
       "      <td>0.211455</td>\n",
       "      <td>3.946276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>0.750595</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.085311</td>\n",
       "      <td>0.377407</td>\n",
       "      <td>0.059383</td>\n",
       "      <td>6.034817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.407241</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>0.333507</td>\n",
       "      <td>0.607249</td>\n",
       "      <td>0.221396</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.876027</td>\n",
       "      <td>3.321619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.548814   0.677817   0.311796   0.906555   0.401260   0.310381   \n",
       "1   0.715189   0.270008   0.696343   0.774047   0.929291   0.373035   \n",
       "2   0.602763   0.735194   0.377752   0.333145   0.099615   0.524970   \n",
       "3   0.544883   0.962189   0.179604   0.081101   0.945302   0.750595   \n",
       "4   0.423655   0.248753   0.024679   0.407241   0.869489   0.333507   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10    target  \n",
       "0   0.174658   0.373216   0.039993    0.810839  4.008168  \n",
       "1   0.327988   0.222864   0.639705    0.348192  3.501436  \n",
       "2   0.680349   0.080532   0.408303    0.211455  3.946276  \n",
       "3   0.063208   0.085311   0.377407    0.059383  6.034817  \n",
       "4   0.607249   0.221396   0.809365    0.876027  3.321619  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8be7ca",
   "metadata": {},
   "source": [
    "Dividimos los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d0d9fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# entrenamiento 70% y prueba 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d226973",
   "metadata": {},
   "source": [
    "Aplicamos RFECV sobre los datos para un modelo de regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fedf56f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero optimo de caracteristicas:  4\n",
      "Caracteristicas seleccionadas:  Index(['feature_1', 'feature_2', 'feature_5', 'feature_7'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importamos el metodo RFECV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# creamos el modelo de regresion lineal\n",
    "model_2 = LinearRegression()\n",
    "\n",
    "# configuramos RFECV\n",
    "rfecv = RFECV(\n",
    "    estimator=model_2,\n",
    "    step=1, # paso para eliminar caracteristicas\n",
    "    cv=5, # numero de pliegues para la validacion cruzada\n",
    "    scoring='neg_mean_squared_error' # uso del MSE negativo como metrica de rendimiento\n",
    ")\n",
    "\n",
    "# ajustar el modelo utilizando RFECV\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# mostrar numero optimo de caracteristicas\n",
    "print('Numero optimo de caracteristicas: ', rfecv.n_features_)\n",
    "# mostrar nombre de las caracteristicas\n",
    "print('Caracteristicas seleccionadas: ', X_train.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b46b0e",
   "metadata": {},
   "source": [
    "El RFECV arroja 4 variables optimas para el modelo de Regresion Lineal: feature 1, 2, 5, y 7, mismas que han sido relacionadas al inicio con la variable objetivo y las esperadas como resultado.\n",
    "\n",
    "RFECV recibe como parametro el *scoring* que en este caso se asigna como el negativo del error cuadratico medio (MSE). Veamos una explicacion del porque:\n",
    "> *Esto se debe a como funciona la API y la convencion de algunas metricas de evaluacion. El MSE es una metrica de error, lo que significa que debemos minimizar este valor para mejorar el rendimiento del modelo. Sim embargo, la mayoria de las funciones de scikit learn estan diseñadas para maximizar la metrica de evaluacion. Por tanto al usar MSE, scikit learn lo convierte en su valor negativo para que la funcion de maximizacion funcione correctamente. Al maximizar el negativo del MSE estamos minimizando el MSE real.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
