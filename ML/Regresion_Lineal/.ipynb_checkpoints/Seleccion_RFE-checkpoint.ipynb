{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36541c37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3fbe050",
   "metadata": {},
   "source": [
    "# Métodos de Selección de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34f0e0",
   "metadata": {},
   "source": [
    "La selección de features es un paso fundamental en el preprocesamiento de datos para modelos de Machine Learning. Consiste en identificar y seleccionar un subconjunto relevante de variables para usar en la construcción de modelos predictivos. La correcta selección de features mejora la precisión del modelo, reduce el sobreajuste, acelera el tiempo de entrenamiento y facilita la interpretación del modelo.\n",
    "\n",
    "En lo que sigue te presento los llamados **Métodos de Wrapper**, los cuales evalúan la calidad de los features utilizando un modelo de Machine Learning específico. Estos suelen ser más precisos, pero también más costosos computacionalmente:\n",
    "\n",
    "- **Eliminación Recursiva de Features (RFE)**\n",
    "- **Eliminación Recursiva de Features con Validación Cruzada (RFECV)**\n",
    "- **Selección Secuencial de Features (SFS)**\n",
    "\n",
    "Veamos de qué se trata cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c4d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c72bd7aa",
   "metadata": {},
   "source": [
    "# 1.- Eliminación Recursiva de Features (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddd4da",
   "metadata": {},
   "source": [
    "Es una técnica utilizada para seleccionar las variables más importantes para un modelo. Su objetivo es eliminar las características menos relevantes, mejorando así el rendimiento del modelo y reduciendo su complejidad.\n",
    "\n",
    "Generalmente, *RFE* se aplica a modelos que pueden proporcionar alguna medida de la importancia de las características como los modelos lineales o arboles de decisión. Entre los modelos donde se puede aplicar tenemos:\n",
    "\n",
    "- Regresión Lineal.\n",
    "- Regresión Logística.\n",
    "- Arboles de decisión.\n",
    "- Bosques aleatorios.\n",
    "- Maquina de vectores de soporte\n",
    "- Entre otros..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95387ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238dff99",
   "metadata": {},
   "source": [
    "## Cómo funciona RFE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cfec8",
   "metadata": {},
   "source": [
    "   Los pasos para entender el funcionamiento del método *RFE* son los siguientes:\n",
    "   \n",
    "   1. **Entrenamiento inicial**: Entrena un modelo utilizando todas las características (Variables predictoras).\n",
    "    \n",
    "    \n",
    "   2. **Evaluación de importancia**: Evalúa la importancia de cada característica medida de diferentes maneras dependiendo del modelo utilizado (coeficientes de la regresión lineal).\n",
    "   \n",
    "    \n",
    "   3. **Eliminación de características**: Elimina las características menos importantes para el modelo.\n",
    "   \n",
    "   \n",
    "   4. **Repetición de pasos**: Repite los pasos del 1 al 3 hasta alcanzar un número predefinido de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95297d6",
   "metadata": {},
   "source": [
    "## Aplicación de RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e88c8",
   "metadata": {},
   "source": [
    "Vamos a aplicar *RFE* sobre un conjunto de datos de prueba de 6 variables, que incluye la variable objetivo, para encontrar las 3 más importantes para un modelo de Rgresión Lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83085d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para generar datos de prueba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# generamos los datos aleatorios de 5 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dac478",
   "metadata": {},
   "source": [
    "Asociamos linealmente a la variable objetivo, 3 de las 5 características: feature 1, 2 y 5. Esto nos asegura que el modelo sólo estará influenciado por estas tres características y entonces, al aplicar *RFE*, nos debe arrojar estas mismas en caso de funcionar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3a8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable objetivo\n",
    "y = 3*X['feature_2'] + 2*X['feature_5'] + X['feature_1'] + np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e8de9",
   "metadata": {},
   "source": [
    "Ahora, juntamos los datos en un Dataframe para mejorar la visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a8c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.401260</td>\n",
       "      <td>3.695163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>3.756831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.735194</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.333145</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>3.532546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>6.072647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.407241</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>3.242399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5    target\n",
       "0   0.548814   0.677817   0.311796   0.906555   0.401260  3.695163\n",
       "1   0.715189   0.270008   0.696343   0.774047   0.929291  3.756831\n",
       "2   0.602763   0.735194   0.377752   0.333145   0.099615  3.532546\n",
       "3   0.544883   0.962189   0.179604   0.081101   0.945302  6.072647\n",
       "4   0.423655   0.248753   0.024679   0.407241   0.869489  3.242399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b57aba",
   "metadata": {},
   "source": [
    "### 1.- Entrenamiento inicial\n",
    "Entrenamos el modelo de regresión lineal con todas las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6eb2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para usar la regresion lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# funcion para entrena el modelo\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    return model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34639d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo\n",
    "modelo = train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0feb3b",
   "metadata": {},
   "source": [
    "### 2.- Evaluación de importancia\n",
    "Para el caso de la regresión, debemos obtener los coeficientes de cada características una vez entrenado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97588cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para obtener los coeficientes de cada caracteristica\n",
    "def evaluate_model(model):\n",
    "    coeficientes = model.coef_\n",
    "    return coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c29a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0169788 , 2.96313024, 0.01281724, 0.04742558, 1.94336239])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coeficiente de las caracteristicas\n",
    "coefi = evaluate_model(modelo)\n",
    "coefi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b02cb",
   "metadata": {},
   "source": [
    "### 3.- Eliminación de características\n",
    "Identificamos la característica con el coeficiente más pequeño (el valor absoluto) y la eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c314b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que determina la caracteristica con menor valor de coeficiente y la elimina\n",
    "def remove_feature(X, coeficientes):\n",
    "    # indice del coficiente mas pequeño\n",
    "    min_indice = np.argmin(np.abs(coeficientes))\n",
    "    # nombre de la caracteristica correspondiente al indice anterior\n",
    "    feature_remove = X.columns[min_indice]\n",
    "    # eliminar caracteristica\n",
    "    X = X.drop(columns=[feature_remove])\n",
    "    # retornar matriz de caracteristica y nombre de la caracteristica eliminada\n",
    "    return X, feature_remove\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d2c34",
   "metadata": {},
   "source": [
    "### 4.- Repetir hasta obtener el número deseado de características\n",
    "\n",
    "Como queremos encontrar las 3 caracteristicas más relvantes para el modelo, repetimos el proceso anterior tres veces. Para automatizar el proceso, procedemos como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd63987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas seleccionadas Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# numero de features a seleccionar\n",
    "n_features = 3\n",
    "\n",
    "# ejecutar proceso hasta llegar a 3 caracteristicas\n",
    "while X.shape[1] > n_features:\n",
    "    modelo = train_model(X,y)\n",
    "    coefi = evaluate_model(modelo)\n",
    "    X, feature_remove = remove_feature(X, coefi)\n",
    "    \n",
    "# mostrar las 3 caracteristicas mas importantes\n",
    "print('Caracteristicas seleccionadas', X.columns)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbad9cc",
   "metadata": {},
   "source": [
    "> Los resultados confirman que los features 1, 2 y 5 son los mas importantea para el modelo de regresión lineal, tal como esperabamos. Y aquí redica la relevancia de este método y es que nos permite encontrar, de un conjunto grande de características, un número específico de ellas importantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bf5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21154913",
   "metadata": {},
   "source": [
    "## Aplicación de RFE con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fca50a",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar la librería Scikit Learn para aplicar este método y simplificar el proceso de eliminación recursiva. Trabajarémos sobre los mismos datos de prueba del ejemplo anterior para hacer una comparación de los resultados de ambos métodos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6017ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.drop(columns=['target'])\n",
    "# variable objetivo\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b1364",
   "metadata": {},
   "source": [
    "Aplicamos RFE con la librería sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6010769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libreria para aplicar RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# crear modelo de regresion\n",
    "modelo_2 = LinearRegression()\n",
    "\n",
    "# Crear el objeto RFE y especificar el numero de caracteristicas deseadas\n",
    "rfe = RFE(estimator=modelo_2, n_features_to_select=3)\n",
    "\n",
    "# ajustar RFE a los datos\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# obtener las caracteristicas seleccionadas por RFE\n",
    "features_select = X.columns[rfe.support_]\n",
    "\n",
    "# mostrar nombre\n",
    "features_select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74def8",
   "metadata": {},
   "source": [
    "> De esta forma, obtenemos las características más importantes para el modelo de regresión, que en este caso son los features 1, 2 y 5, coincidiendo con los resultados del ejemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd8834c",
   "metadata": {},
   "source": [
    "# 2.- Eliminación Recursiva de Features con Validación Cruzada (RFECV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85377f1f",
   "metadata": {},
   "source": [
    "Es una técnica de selección de características que mejora la metodología *RFE* al incoporar la validación cruzada para seleccionar automáticamente el número óptimo de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8514ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491bfde4",
   "metadata": {},
   "source": [
    "## Cómo funciona RFECV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b1e94",
   "metadata": {},
   "source": [
    "1. **Entrenamiento del modelo**: Similar a RFE, entrena el modelo usando todas las características.\n",
    "\n",
    "\n",
    "2. **Validación cruzada**: Utiliza la validación cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.\n",
    "\n",
    "\n",
    "3. **Eliminación de características**: Elimina la característica menos importante y evalúa el modelo usando validación cruzada.\n",
    "\n",
    "\n",
    "4. **Repetición de pasos**: Repite los pasos del 1 hasta el 3 hasta que se encuentre el conjunto óptimo de características que maximiza el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde949ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4488437a",
   "metadata": {},
   "source": [
    "## Aplicación de RFECV con Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b952a",
   "metadata": {},
   "source": [
    "Vamos a utilizar un conjunto de datos de prueba de 11 características, incluyendo la variable objetivo, para aplicar RFECV y obtener las características mas importantes para un modelo de Regresión Lineal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71998070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 10 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100),\n",
    "    'feature_6': np.random.rand(100),\n",
    "    'feature_7': np.random.rand(100),\n",
    "    'feature_8': np.random.rand(100),\n",
    "    'feature_9': np.random.rand(100),\n",
    "    'feature_10': np.random.rand(100)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6d6c6",
   "metadata": {},
   "source": [
    "Relacionamos la variable objetivo con 4 características: feature 1, 2, 5 y 7. Esto asegura que de las 10 caracteristicas, estas 4 influencian el modelo y por tanto, al aplicar RFECV, nos debe arrojar las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f2742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.008168\n",
       "1    3.501436\n",
       "2    3.946276\n",
       "3    6.034817\n",
       "4    3.321619\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable objetivo\n",
    "y = (\n",
    "    3*X['feature_2'] + \n",
    "    2*X['feature_5'] + \n",
    "    X['feature_1'] + \n",
    "    X['feature_7']*X['feature_7'] +\n",
    "    np.random.rand(100)\n",
    ")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54280bb",
   "metadata": {},
   "source": [
    "Juntamos los datos en un Dataframe para visualizarlos mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df799ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.401260</td>\n",
       "      <td>0.310381</td>\n",
       "      <td>0.174658</td>\n",
       "      <td>0.373216</td>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.810839</td>\n",
       "      <td>4.008168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.373035</td>\n",
       "      <td>0.327988</td>\n",
       "      <td>0.222864</td>\n",
       "      <td>0.639705</td>\n",
       "      <td>0.348192</td>\n",
       "      <td>3.501436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.735194</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.333145</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>0.524970</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.408303</td>\n",
       "      <td>0.211455</td>\n",
       "      <td>3.946276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>0.750595</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.085311</td>\n",
       "      <td>0.377407</td>\n",
       "      <td>0.059383</td>\n",
       "      <td>6.034817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.407241</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>0.333507</td>\n",
       "      <td>0.607249</td>\n",
       "      <td>0.221396</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.876027</td>\n",
       "      <td>3.321619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.548814   0.677817   0.311796   0.906555   0.401260   0.310381   \n",
       "1   0.715189   0.270008   0.696343   0.774047   0.929291   0.373035   \n",
       "2   0.602763   0.735194   0.377752   0.333145   0.099615   0.524970   \n",
       "3   0.544883   0.962189   0.179604   0.081101   0.945302   0.750595   \n",
       "4   0.423655   0.248753   0.024679   0.407241   0.869489   0.333507   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10    target  \n",
       "0   0.174658   0.373216   0.039993    0.810839  4.008168  \n",
       "1   0.327988   0.222864   0.639705    0.348192  3.501436  \n",
       "2   0.680349   0.080532   0.408303    0.211455  3.946276  \n",
       "3   0.063208   0.085311   0.377407    0.059383  6.034817  \n",
       "4   0.607249   0.221396   0.809365    0.876027  3.321619  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8be7ca",
   "metadata": {},
   "source": [
    "Dividimos los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d9fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# entrenamiento 70% y prueba 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d226973",
   "metadata": {},
   "source": [
    "Aplicamos RFECV sobre el modelo de regresión lineal indicando el paso, el número de pliegues de la validación cruzada y la métrica a utilizar para medir el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fedf56f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero optimo de caracteristicas:  4\n",
      "Caracteristicas seleccionadas:  Index(['feature_1', 'feature_2', 'feature_5', 'feature_7'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importamos el metodo RFECV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# creamos el modelo de regresion lineal\n",
    "model_2 = LinearRegression()\n",
    "\n",
    "# configuramos RFECV\n",
    "rfecv = RFECV(\n",
    "    estimator=model_2,\n",
    "    step=1, # paso para eliminar caracteristicas\n",
    "    cv=5, # numero de pliegues para la validacion cruzada\n",
    "    scoring='neg_mean_squared_error' # uso del MSE negativo como metrica de rendimiento\n",
    ")\n",
    "\n",
    "# ajustar RFECV a los datos\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# mostrar numero optimo de caracteristicas\n",
    "print('Numero optimo de caracteristicas: ', rfecv.n_features_)\n",
    "# mostrar nombre de las caracteristicas\n",
    "print('Caracteristicas seleccionadas: ', X_train.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b46b0e",
   "metadata": {},
   "source": [
    "El RFECV arroja 4 variables óptimas para el modelo de Regresión Lineal: feature 1, 2, 5, y 7, mismas que han sido relacionadas al inicio con la variable objetivo y las esperadas como resultado.\n",
    "\n",
    "RFECV recibe como parámetro el *scoring* que en este caso se asigna como el negativo del error cuadratico medio (MSE). Veamos una explicación del porqué:\n",
    "> *Esto se debe a como funciona la API y la convención de algunas métricas de evaluación. El MSE es una métrica de error, lo que significa que debemos minimizar este valor para mejorar el rendimiento del modelo. Sim embargo, la mayoría de las funciones de Scikit learn están diseñadas para maximizar la métrica de evaluación. Por tanto, al usar MSE, Scikit Learn lo convierte en su valor negativo para que la función de maximización funcione correctamente. Al maximizar el negativo del MSE estamos minimizando el MSE real.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b425b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72b0853",
   "metadata": {},
   "source": [
    "# 3.- Selección Secuencial de Features (SFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41726e33",
   "metadata": {},
   "source": [
    "Es una técnica de selección de características usada para reducir el número de las mismas en un modelo de manera más eficiente. Realiza la selección de manera secuencial, es decir, añade o elimina características una por una basandose en su impacto en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b50e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa2401bd",
   "metadata": {},
   "source": [
    "## Cómo funciona SFS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd367a0",
   "metadata": {},
   "source": [
    "La implementación de SFS va a depender del tipo de selección que se realice: Forward Selection (Seleccion hacia adelante) o Backward Selection (Selección hacia atrás). Veámos el paso a paso de cada método:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5fefc",
   "metadata": {},
   "source": [
    "### **Forward Selection**\n",
    "\n",
    "1.- **Inicialización**: Comienza con un modelo vacío, sin variables predictoras.\n",
    "\n",
    "2.- **Evaluación de características**: Evalúa todas las características individualmente y selecciona la que mejora el rendimiento del modelo.\n",
    "\n",
    "3.- **Agregar caracerística**: agrega la característica seleccionada al modelo.\n",
    "\n",
    "4.- **Repetir**: Repite el proceso, evaluando las características restantes en combinación con las ya seleccionadas hasta alcanzar un número máximo de características determinadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2b608",
   "metadata": {},
   "source": [
    "### **Backward Selection**\n",
    "\n",
    "1.-**Inicialización**: Comienza con todas las caracteristicas disponibles.\n",
    "\n",
    "2.- **Evaluación de características**: Evalúa todas las características individualmente y selecciona la que tiene el menor impacto negativo en el rendimiento del modelo.\n",
    "\n",
    "3.- **Eliminar característica**: Elimina la característica seleccionada del modelo.\n",
    "\n",
    "4.- **Repetir**: Repite el proceso hasta alcanzar un número de características determinadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b60ee",
   "metadata": {},
   "source": [
    "En general, la selección hacia adelante y hacia atrás no arroja resultados equivalentes debido a la forma en que van apareciendo las variables. Además, una puede ser mucho más rápida que la otra según la cantidad solicitada de características: si tenemos 10 características y pedimos 7 características seleccionadas, la selección hacia adelante necesitaría realizar 7 iteraciones mientras que la selección hacia atrás solo necesitaría realizar 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a387c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9a02bac",
   "metadata": {},
   "source": [
    "## Diferencias entre SFS y RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc84dfc",
   "metadata": {},
   "source": [
    "- *SFS* ofrece tanto selección hacia adelante como hacia atrás, proporcinando mayor flexibilidad en la dirección del proceso de selección.\n",
    "\n",
    "- *SFS* no requiere que el modelo exponga un atributo para mostrar las características seleccionadas.\n",
    "\n",
    "- *SFS* puede ser más eficiente en ciertos casos ya que evalúa incrementos específicos en el rendimiento del modelo.\n",
    "\n",
    "- *RFE* puede ser computacionalmente costoso debido a la necesidad de recalcular la importancia de las características y reentrenar el modelo en cada iteración.\n",
    "\n",
    "- *SFS* puede ser más lento ya que debe evaluar más modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6b525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32a0c6c8",
   "metadata": {},
   "source": [
    "## Aplicación de SFS con Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7b36b",
   "metadata": {},
   "source": [
    "Vamos a utilizar el conjunto de datos de prueba del ejemplo anterior y vamos aplicar el método *SFS* tanto hacia adelante como hacia atrás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6583817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 10 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100),\n",
    "    'feature_6': np.random.rand(100),\n",
    "    'feature_7': np.random.rand(100),\n",
    "    'feature_8': np.random.rand(100),\n",
    "    'feature_9': np.random.rand(100),\n",
    "    'feature_10': np.random.rand(100)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07aa65",
   "metadata": {},
   "source": [
    "Relacionamos la variable objetivo con 4 características: feature 1, 2, 5 y 7. Esto asegura que de las 10 caracteristicas, solo 4 influencian el modelo y por tanto, al aplicar *SFS* sólo algunas de estas, dependiendo de la cantidad que sean solicitadas, serán devueltas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad0e4329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.008168\n",
       "1    3.501436\n",
       "2    3.946276\n",
       "3    6.034817\n",
       "4    3.321619\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable objetivo\n",
    "y = (\n",
    "    3*X['feature_2'] + \n",
    "    2*X['feature_5'] + \n",
    "    X['feature_1'] + \n",
    "    X['feature_7']*X['feature_7'] +\n",
    "    np.random.rand(100)\n",
    ")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f1a47",
   "metadata": {},
   "source": [
    "Dividimos los datos entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8498a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# entrenamiento 70% y prueba 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a69a7",
   "metadata": {},
   "source": [
    "Aplicamos SFS hacia adelante para un modelo de regresión lineal y solicitamos las 4 características más importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8cfc846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_5', 'feature_7'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libreria para aplicar SFS\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "model_3 = LinearRegression()\n",
    "\n",
    "# configurar el selector de caracteristicas sencuencial\n",
    "sfs = SequentialFeatureSelector(\n",
    "    model_3,\n",
    "    n_features_to_select=4, #cantidad de caracteristicas\n",
    "    direction='forward', # direccion de seleccion\n",
    "    cv=5 # numero de validaciones cruzadas\n",
    "    )\n",
    "\n",
    "# ajustamos el selector a los datos de entrenamiento\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# obtener las caracteristicas seleccionadas\n",
    "selected_features = X_train.columns[sfs.get_support()]\n",
    "\n",
    "# mostras caracteristicas\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a02c6e",
   "metadata": {},
   "source": [
    "> Vemos que las características seleccionadas son las mismas que están relacionadas con el modelo, por tanto, confirmamos que el método funciona correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2588f5",
   "metadata": {},
   "source": [
    "Ahora, aplicamos SFS hacia atrás para un modelo de regresión lineal y una cantidad de 3 características. Esta elección de parámetros, hará que el procesos SFS demore un poco más debido a que deben realizar más iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "595aea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_2', 'feature_5', 'feature_7'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear el modelo de regresión lineal\n",
    "model_4 = LinearRegression()\n",
    "\n",
    "# configurar el selector de caracteristicas sencuencial\n",
    "sfs = SequentialFeatureSelector(\n",
    "    model_4,\n",
    "    n_features_to_select=3, #cantidad de caracteristicas\n",
    "    direction='backward', # direccion de seleccion\n",
    "    cv=5 # numero de validaciones cruzadas\n",
    "                               )\n",
    "\n",
    "# ajustamos el selector a los datos de entrenamiento\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# obtener las caracteristicas seleccionadas\n",
    "selected_features = X_train.columns[sfs.get_support()]\n",
    "\n",
    "# mostras caracteristicas\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b195c",
   "metadata": {},
   "source": [
    "> Las características seleccionadas por SFS hacia atrás están relacionadas con la variable objetivo del modelo, por tanto, confirmamos que el método funciona correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae412756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
