{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72bd7aa",
   "metadata": {},
   "source": [
    "# Clasificador de funciones con eliminacion recursiva (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddd4da",
   "metadata": {},
   "source": [
    "Es una tecnica utilizada para seleccionar las caracteristicas mas importantes de un conjunto de datos. Su objetivo es eliminar las caracteristicas menos relevantes, mejorando asi el rendimiento del modelo y reduciendo su complejidad.\n",
    "\n",
    "Generalmente, RFE se aplica a modelos que pueden proporcionar alguna medida de la importancia de las caracteristicas como los modelos lineales o arboles de decision. Entre los modelos donde se puede aplicar tenemos:\n",
    "\n",
    "- Regresion Lineal\n",
    "- Regresion Logistica\n",
    "- Arboles de decision\n",
    "- Bosques aleatorios\n",
    "- Maquina de vectores de soporte\n",
    "- Entre otros..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dff99",
   "metadata": {},
   "source": [
    "# Como funciona RFE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cfec8",
   "metadata": {},
   "source": [
    "   1. **Entrenamiento inicial**: Entrena un modelo utilizando todas las caracteristicas (Variables predictoras)\n",
    "    \n",
    "    \n",
    "   2. **Evaluacion de Importancia**: Evalua la importancia de cada caracteristica. Esta importancia se puede medir de diferentes maneras dependiendo del modelo utilizado (coeficientes de la regresion lineal)\n",
    "   \n",
    "    \n",
    "   3. **Eliminacion de Caracteristicas**: Elimina las caracteristicas menos importantes para el modelo\n",
    "   \n",
    "   \n",
    "   4. **Repeticion de pasos**: Repite los pasos de 1 a 3 hasta alcanzar un numero predefinido de caracteristicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95297d6",
   "metadata": {},
   "source": [
    "# Aplicacion de RFE sobre un modelo de Regresion Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e88c8",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un conjunto de 5 caracteristicas y vamos a usar RFE para seleccionar las 3 caracteristicas mas importantes. Generamos el conjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83085d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos de prueba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 5 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100)\n",
    "})\n",
    "\n",
    "# variable objetivo\n",
    "# la asociamos linealmente con 3 de las 5 caracteristicas\n",
    "y = 3*X['feature_2'] + 2*X['feature_5'] + X['feature_1'] + np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d01ea",
   "metadata": {},
   "source": [
    "Al asociar la variable objetivo con 3 de las 5 features nos aseguramos que el modelo solo va a estar influenciado por estas tres caracteristicas lo cual debe verse reflejado al aplicar RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a8c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.401260</td>\n",
       "      <td>3.695163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>3.756831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.735194</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.333145</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>3.532546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>6.072647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.407241</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>3.242399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5    target\n",
       "0   0.548814   0.677817   0.311796   0.906555   0.401260  3.695163\n",
       "1   0.715189   0.270008   0.696343   0.774047   0.929291  3.756831\n",
       "2   0.602763   0.735194   0.377752   0.333145   0.099615  3.532546\n",
       "3   0.544883   0.962189   0.179604   0.081101   0.945302  6.072647\n",
       "4   0.423655   0.248753   0.024679   0.407241   0.869489  3.242399"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# juntamos los datos en un dataframe para mejorar la visualizacion de los datos\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b57aba",
   "metadata": {},
   "source": [
    "### 1.- Entrenamiento inicial\n",
    "Entrenamos el modelo de regresion lineal con todas las caracteristicas y calculamos la importancia de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6eb2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para usar la regresion lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# funcion para entrena el modelo\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    return model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34639d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo\n",
    "modelo = train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0feb3b",
   "metadata": {},
   "source": [
    "### 2.- Evaluacion de importancia\n",
    "Para el caso de la regresion, debemos obtener los coeficientes de cada caracteristicas una vez entrenado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97588cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para obtener los coeficientes de cada caracteristica\n",
    "def evaluate_model(model):\n",
    "    coeficientes = model.coef_\n",
    "    return coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c29a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0169788 , 2.96313024, 0.01281724, 0.04742558, 1.94336239])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coeficiente de las caracteristicas\n",
    "coefi = evaluate_model(modelo)\n",
    "coefi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b02cb",
   "metadata": {},
   "source": [
    "### 3.- Eliminacion de caracteristicas\n",
    "Identificamos la caracteristica con el coeficiente mas pequeño (el valor absoluto) y la eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c314b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que determina la caracteristica con menor valor de coeficiente y la elimina\n",
    "def remove_feature(X, coeficientes):\n",
    "    # indice del coficiente mas pequeño\n",
    "    min_indice = np.argmin(np.abs(coeficientes))\n",
    "    # nombre de la caracteristica correspondiente al indice anterior\n",
    "    feature_remove = X.columns[min_indice]\n",
    "    # eliminar caracteristica\n",
    "    X = X.drop(columns=[feature_remove])\n",
    "    # retornar matriz de caracteristica y nombre de la caracteristica eliminada\n",
    "    return X, feature_remove\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d2c34",
   "metadata": {},
   "source": [
    "### 4.- Repetir hasta obtener el numero deseado de caracteristicas\n",
    "\n",
    "Inicialmente dijimos que vamos a obtener las 3 caracteristicas mas importantes. Entonces, repetimos el proceso del 1 al 3 hasta obtener las tres caracteristicas. Para automatizar el proceso, procedemos como sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd63987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas seleccionadas Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# numero de features a seleccionar\n",
    "n_features = 3\n",
    "\n",
    "# ejecutar proceso hasta llegar a 3 caracteristicas\n",
    "while X.shape[1] > n_features:\n",
    "    modelo = train_model(X,y)\n",
    "    coefi = evaluate_model(modelo)\n",
    "    X, feature_remove = remove_feature(X, coefi)\n",
    "    \n",
    "# mostrar las 3 caracteristicas mas importantes\n",
    "print('Caracteristicas seleccionadas', X.columns)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8617c8",
   "metadata": {},
   "source": [
    "Los resultados confirman que los features 1, 2 y 5 son los que realmente influyen sobre el modelo de regresion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bf5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21154913",
   "metadata": {},
   "source": [
    "# Aplicacion de RFE con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fca50a",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar la libreria Scikit Learn para aplicar este metodo y simplificar el proceso de eliminacion recursiva. Trabajaremos sobre los mismos datos de prueba del ejemplo anterior para comparar los resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6017ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.drop(columns=['target'])\n",
    "# variable objetivo\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c452f",
   "metadata": {},
   "source": [
    "Aplicamos RFE con la libreria sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "306aa779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libreria para aplicar RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# crear modelo de regresion\n",
    "modelo_2 = LinearRegression()\n",
    "\n",
    "# Crear el objeto RFE y especificar el numero de caracteristicas deseadas\n",
    "rfe = RFE(estimator=modelo_2, n_features_to_select=3)\n",
    "\n",
    "# ajustar RFE a los datos\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# obtener las caracteristicas seleccionadas por RFE\n",
    "features_select = X.columns[rfe.support_]\n",
    "\n",
    "# mostrar nombre\n",
    "features_select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b1df4d",
   "metadata": {},
   "source": [
    "De esta forma, obtenemos los features mas importantes para el modelo de regresion, que en este caso son los features 1, 2 y 5, coincidiendo con los resultados del ejemplo anterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
