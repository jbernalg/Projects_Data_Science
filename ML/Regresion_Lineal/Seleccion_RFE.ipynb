{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72bd7aa",
   "metadata": {},
   "source": [
    "# Eliminacion Recursiva de Features (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddd4da",
   "metadata": {},
   "source": [
    "Es una tecnica utilizada para seleccionar las caracteristicas mas importantes de un conjunto de datos. Su objetivo es eliminar las caracteristicas menos relevantes, mejorando asi el rendimiento del modelo y reduciendo su complejidad.\n",
    "\n",
    "Generalmente, RFE se aplica a modelos que pueden proporcionar alguna medida de la importancia de las caracteristicas como los modelos lineales o arboles de decision. Entre los modelos donde se puede aplicar tenemos:\n",
    "\n",
    "- Regresion Lineal\n",
    "- Regresion Logistica\n",
    "- Arboles de decision\n",
    "- Bosques aleatorios\n",
    "- Maquina de vectores de soporte\n",
    "- Entre otros..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95387ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238dff99",
   "metadata": {},
   "source": [
    "## Como funciona RFE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cfec8",
   "metadata": {},
   "source": [
    "   1. **Entrenamiento inicial**: Entrena un modelo utilizando todas las caracteristicas (Variables predictoras)\n",
    "    \n",
    "    \n",
    "   2. **Evaluacion de Importancia**: Evalua la importancia de cada caracteristica. Esta importancia se puede medir de diferentes maneras dependiendo del modelo utilizado (coeficientes de la regresion lineal)\n",
    "   \n",
    "    \n",
    "   3. **Eliminacion de Caracteristicas**: Elimina las caracteristicas menos importantes para el modelo\n",
    "   \n",
    "   \n",
    "   4. **Repeticion de pasos**: Repite los pasos de 1 a 3 hasta alcanzar un numero predefinido de caracteristicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95297d6",
   "metadata": {},
   "source": [
    "## Aplicacion de RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e88c8",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un conjunto de 5 caracteristicas y vamos a usar RFE para seleccionar las 3 caracteristicas mas importantes. Generamos el conjunto de datos de prueba convenientemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83085d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos de prueba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 5 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100)\n",
    "})\n",
    "\n",
    "# variable objetivo\n",
    "# la asociamos linealmente con 3 de las 5 caracteristicas\n",
    "y = 3*X['feature_2'] + 2*X['feature_5'] + X['feature_1'] + np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dac478",
   "metadata": {},
   "source": [
    "Al asociar la variable objetivo con 3 de las 5 features nos aseguramos que el modelo solo va a estar influenciado por estas tres caracteristicas lo cual debe verse reflejado al aplicar RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a8c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.401260</td>\n",
       "      <td>3.695163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>3.756831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.735194</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.333145</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>3.532546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>6.072647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.248753</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.407241</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>3.242399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5    target\n",
       "0   0.548814   0.677817   0.311796   0.906555   0.401260  3.695163\n",
       "1   0.715189   0.270008   0.696343   0.774047   0.929291  3.756831\n",
       "2   0.602763   0.735194   0.377752   0.333145   0.099615  3.532546\n",
       "3   0.544883   0.962189   0.179604   0.081101   0.945302  6.072647\n",
       "4   0.423655   0.248753   0.024679   0.407241   0.869489  3.242399"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# juntamos los datos en un dataframe para mejorar la visualizacion de los datos\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b57aba",
   "metadata": {},
   "source": [
    "### 1.- Entrenamiento inicial\n",
    "Entrenamos el modelo de regresion lineal con todas las caracteristicas y calculamos la importancia de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6eb2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para usar la regresion lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# funcion para entrena el modelo\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    return model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34639d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo\n",
    "modelo = train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0feb3b",
   "metadata": {},
   "source": [
    "### 2.- Evaluacion de importancia\n",
    "Para el caso de la regresion, debemos obtener los coeficientes de cada caracteristicas una vez entrenado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97588cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para obtener los coeficientes de cada caracteristica\n",
    "def evaluate_model(model):\n",
    "    coeficientes = model.coef_\n",
    "    return coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c29a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0169788 , 2.96313024, 0.01281724, 0.04742558, 1.94336239])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coeficiente de las caracteristicas\n",
    "coefi = evaluate_model(modelo)\n",
    "coefi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b02cb",
   "metadata": {},
   "source": [
    "### 3.- Eliminacion de caracteristicas\n",
    "Identificamos la caracteristica con el coeficiente mas pequeño (el valor absoluto) y la eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c314b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que determina la caracteristica con menor valor de coeficiente y la elimina\n",
    "def remove_feature(X, coeficientes):\n",
    "    # indice del coficiente mas pequeño\n",
    "    min_indice = np.argmin(np.abs(coeficientes))\n",
    "    # nombre de la caracteristica correspondiente al indice anterior\n",
    "    feature_remove = X.columns[min_indice]\n",
    "    # eliminar caracteristica\n",
    "    X = X.drop(columns=[feature_remove])\n",
    "    # retornar matriz de caracteristica y nombre de la caracteristica eliminada\n",
    "    return X, feature_remove\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d2c34",
   "metadata": {},
   "source": [
    "### 4.- Repetir hasta obtener el numero deseado de caracteristicas\n",
    "\n",
    "Inicialmente dijimos que vamos a obtener las 3 caracteristicas mas importantes. Entonces, repetimos el proceso del 1 al 3 hasta obtener las tres caracteristicas. Para automatizar el proceso, procedemos como sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd63987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas seleccionadas Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# numero de features a seleccionar\n",
    "n_features = 3\n",
    "\n",
    "# ejecutar proceso hasta llegar a 3 caracteristicas\n",
    "while X.shape[1] > n_features:\n",
    "    modelo = train_model(X,y)\n",
    "    coefi = evaluate_model(modelo)\n",
    "    X, feature_remove = remove_feature(X, coefi)\n",
    "    \n",
    "# mostrar las 3 caracteristicas mas importantes\n",
    "print('Caracteristicas seleccionadas', X.columns)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbad9cc",
   "metadata": {},
   "source": [
    "Los resultados confirman que los features 1, 2 y 5 son los que realmente influyen sobre el modelo de regresion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bf5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21154913",
   "metadata": {},
   "source": [
    "## Aplicacion de RFE con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fca50a",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar la libreria Scikit Learn para aplicar este metodo y simplificar el proceso de eliminacion recursiva. Trabajaremos sobre los mismos datos de prueba del ejemplo anterior para comparar los resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6017ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.drop(columns=['target'])\n",
    "# variable objetivo\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b1364",
   "metadata": {},
   "source": [
    "Aplicamos RFE con la libreria sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6010769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_5'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libreria para aplicar RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# crear modelo de regresion\n",
    "modelo_2 = LinearRegression()\n",
    "\n",
    "# Crear el objeto RFE y especificar el numero de caracteristicas deseadas\n",
    "rfe = RFE(estimator=modelo_2, n_features_to_select=3)\n",
    "\n",
    "# ajustar RFE a los datos\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# obtener las caracteristicas seleccionadas por RFE\n",
    "features_select = X.columns[rfe.support_]\n",
    "\n",
    "# mostrar nombre\n",
    "features_select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74def8",
   "metadata": {},
   "source": [
    "De esta forma, obtenemos los features mas importantes para el modelo de regresion, que en este caso son los features 1, 2 y 5, coincidiendo con los resultados del ejemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd8834c",
   "metadata": {},
   "source": [
    "# Eliminacion Recursiva de Features con Validacion Cruzada (RFECV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85377f1f",
   "metadata": {},
   "source": [
    "Es una tecnica de seleccion de caracteristicas que mejora la metodologia RFE al incoporar la validacion cruzada para seleccionar automaticamente el numero optimo de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8514ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491bfde4",
   "metadata": {},
   "source": [
    "## Como funciona RFECV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b1e94",
   "metadata": {},
   "source": [
    "1. **Entrenamiento del modelo**: Similar a RFE, entrena el modelo usando todas las caracteristicas\n",
    "\n",
    "\n",
    "2. **Validacion Cruzada**: Utiliza la validacion cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.\n",
    "\n",
    "\n",
    "3. **Eliminacion de caracteristicas**: Elimina la caracteristica menos importante y evalua el modelo usando validacion cruzada.\n",
    "\n",
    "\n",
    "4. **Repeticion de pasos**: Repite los pasos 1 hasta 3 hasta que se encuentre el conjunto optimo de caracteristicas que maximiza el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde949ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69310128",
   "metadata": {},
   "source": [
    "## Aplicacion de RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a066ea0",
   "metadata": {},
   "source": [
    "Para implementar este metodos, vamos a utilizar los datos de Boston Housing de la libreria de Scikit Learn. Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e422c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbernal/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# cargamos los datos\n",
    "boston = load_boston()\n",
    "\n",
    "# features\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "# variable objetivo\n",
    "y = pd.Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89ef37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a391d2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa29639",
   "metadata": {},
   "source": [
    "Dividimos los datos en datos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adeccb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# entrenamiento 70% y prueba 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2943773",
   "metadata": {},
   "source": [
    "Creamos una funcion que entrena el modelo de regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e4005b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para entrenar el modelo de regresion\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def train_model(X, y):\n",
    "    # agregar una constante al intercepto\n",
    "    X = sm.add_constant(X)\n",
    "    # creacion y ajuste del modelo con minimos cuadrados ordinarios (OLS)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60fccd",
   "metadata": {},
   "source": [
    "Creamos una funcion que realice la validacion cruzada y calcule el error cuadratico medio promedio (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e127c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para dividir los datos en grupos\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_val(model, X, y, cv=5):\n",
    "    # numero de pliegues de datos\n",
    "    kf = KFold(n_splits=cv)\n",
    "    # lista para almacenar valores de MSE de cada pliegue\n",
    "    mse_score = []\n",
    "    \n",
    "    # iterar sobre los pliegues\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # caracteristicas de los conjuntos de entrenamiento y validacion\n",
    "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "        # variables objetivo de los conjuntos de entrenamiento y validacion\n",
    "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # entrenamiento del modelo para cada pliegue\n",
    "        model_fold = train_model(X_train_fold, y_train_fold)\n",
    "        # prediccion para el conjunto de validacion\n",
    "        y_pred_fold = model_fold.predict(sm.add_constant(X_val_fold))\n",
    "        # calculos de la metrica MSE\n",
    "        mse_fold = np.mean((y_val_fold - y_pred_fold)**2)\n",
    "        mse_score.append(mse_fold)\n",
    "        \n",
    "    return np.mean(mse_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582ed01",
   "metadata": {},
   "source": [
    "Creamos una funcion que realice todo el proceso de RFECV y devuelva los mejores features junto a su respectiva puntuacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87552106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfecv(X, y, cv=5):\n",
    "    # lista de caracteristicas disponibles\n",
    "    features_disp = list(X.columns)\n",
    "    # inicializa la mejor puntuacion como infinito representando la peor puntuacion posible\n",
    "    mejor_punt = float('inf')\n",
    "    # inicializa las mejores features\n",
    "    mejor_features = None\n",
    "    \n",
    "    # bucle que se ejecuta mientras haya caracteristicas para evaluar\n",
    "    while len(features_disp) > 0:\n",
    "        # lista para almacenar las puntuaciones de la validacion cruzada\n",
    "        scores = []\n",
    "        # lista para almacenar los modelos entrenados y las caracteristicas utilizadas\n",
    "        models = []\n",
    "        \n",
    "        # itera sobre cada feature de features_disp\n",
    "        for feature in features_disp:\n",
    "            # lista de features excluyendo la actual\n",
    "            features_usar = [f for f in features_disp if f != feature]\n",
    "            # subconjunto de X que solo contiene las features_usar\n",
    "            X_subset = X[features_usar]\n",
    "            # entrenar el modelo usando X_subset y y\n",
    "            model = train_model(X_subset, y)\n",
    "            # obtener la puntuacion promedio de la validacion cruzada\n",
    "            score = cross_val(model, X_subset, y, cv=cv)\n",
    "            # almacenar resultados de la metrica y el modelo entrenado\n",
    "            scores.append(score)\n",
    "            models.append((model, features_usar))\n",
    "            \n",
    "        # mejor puntuacion de la iteracion    \n",
    "        mejor_it_punt = min(scores)\n",
    "        # indice de la mejor puntuacion\n",
    "        mejor_it_indice = scores.index(mejor_it_punt)\n",
    "        \n",
    "        # actualizacion de la mejor puntuacion y features\n",
    "        if mejor_it_punt < mejor_punt:\n",
    "            mejor_punt = mejor_it_punt\n",
    "            mejor_features = models[mejor_it_indice][1]\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # elimina la peor puntuacion de la iteracion actual\n",
    "        peor_feature = features_disp[scores.index(max(scores))]\n",
    "        features_disp.remove(peor_feature)\n",
    "        \n",
    "    return mejor_features, mejor_punt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4995e0",
   "metadata": {},
   "source": [
    "Ahora, aplicamos RFECV a los datos y obtenemos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c7ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores features seleccionadas:  ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "Mejor puntuacion de validacion cruzada (MSE):  22.447996725679257\n"
     ]
    }
   ],
   "source": [
    "mejores_features, mejor_score = rfecv(X_train, y_train, cv=7)\n",
    "print('Mejores features seleccionadas: ', mejores_features)\n",
    "print('Mejor puntuacion de validacion cruzada (MSE): ', mejor_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49f331",
   "metadata": {},
   "source": [
    "En este caso se obtuvieron 12 caracteristicas optimas seleccionadas por el metodo RFECV implementado de forma manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b31048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4488437a",
   "metadata": {},
   "source": [
    "## Aplicacion de RFECV con Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b952a",
   "metadata": {},
   "source": [
    "Vamos a utilizar los datos del ejemplo anterior para aplicarles el metodo RFECV de Scikit Learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08358c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.62864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>5.019</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4394</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>34.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.11460</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464</td>\n",
       "      <td>6.538</td>\n",
       "      <td>58.7</td>\n",
       "      <td>3.9175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>394.96</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.55778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.335</td>\n",
       "      <td>98.2</td>\n",
       "      <td>2.1107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>394.67</td>\n",
       "      <td>16.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.06466</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>6.345</td>\n",
       "      <td>20.1</td>\n",
       "      <td>7.8278</td>\n",
       "      <td>5.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>368.24</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.09299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.961</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0869</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>378.09</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "141  1.62864   0.0  21.89   0.0  0.624  5.019  100.0  1.4394  4.0  437.0   \n",
       "272  0.11460  20.0   6.96   0.0  0.464  6.538   58.7  3.9175  3.0  223.0   \n",
       "135  0.55778   0.0  21.89   0.0  0.624  6.335   98.2  2.1107  4.0  437.0   \n",
       "298  0.06466  70.0   2.24   0.0  0.400  6.345   20.1  7.8278  5.0  358.0   \n",
       "122  0.09299   0.0  25.65   0.0  0.581  5.961   92.9  2.0869  2.0  188.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "141     21.2  396.90  34.41  \n",
       "272     18.6  394.96   7.73  \n",
       "135     21.2  394.67  16.96  \n",
       "298     14.8  368.24   4.97  \n",
       "122     19.1  378.09  17.93  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datos de entrenamiento\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903ce1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141    14.4\n",
       "272    24.4\n",
       "135    18.1\n",
       "298    22.5\n",
       "122    20.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13678f38",
   "metadata": {},
   "source": [
    "Aplicamos RFECV a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac608c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero optimo de caracteristicas:  12\n",
      "Caracteristicas seleccionadas:  Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importamos el metodo RFECV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# creamos el modelo de regresion lineal\n",
    "model_2 = LinearRegression()\n",
    "\n",
    "# configuramos RFECV\n",
    "rfecv = RFECV(\n",
    "    estimator=model_2,\n",
    "    step=1, # paso para eliminar caracteristicas\n",
    "    cv=7, # numero de pliegues para la validacion cruzada\n",
    "    scoring='neg_mean_squared_error' # uso del MSE negativo como metrica de rendimiento\n",
    ")\n",
    "\n",
    "# ajustar el modelo utilizando RFECV\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# mostrar numero optimo de caracteristicas\n",
    "print('Numero optimo de caracteristicas: ', rfecv.n_features_)\n",
    "# mostrar nombre de las caracteristicas\n",
    "print('Caracteristicas seleccionadas: ', X_train.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721591fa",
   "metadata": {},
   "source": [
    "Vemos que, al igual que el ejemplo anterior, el RFECV arroja 12 variables optimas para entrenar el modelo. Al utilizar el metodo de Scikit Learn simplificamos considerablemente el proceso de RFECV pero es importante entender que hay detras y fue por eso que lo implementamos anteriormente de forma manual.\n",
    "\n",
    "RFECV recibe como parametro el *scoring* que en este caso se asigna como el negativo del error cuadratico medio (MSE). Veamos una explicacion del porque:\n",
    "> Esto se debe a como funciona la API y la convencion de algunas metricas de evaluacion. El MSe es una metrica de error, lo que significa que debemos minimizar este valor para mejorar el rendimiento del modelo. Sim embargo, la mayoria de las funciones de scikit learn estan diseñadas para maximizar la metrica de evaluacion. Por tanto al usar MSE, scikit learn lo convierte en su valor negativo para que la funcion de maximizacion funcione correctamente. Al maximizar el negativo del MSE estamos minimizando el MSE real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b6fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71998070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.008232\n",
       "1    3.763218\n",
       "2    4.014345\n",
       "3    6.088574\n",
       "4    3.851811\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# semilla\n",
    "np.random.seed(0)\n",
    "\n",
    "# 10 caracteristicas\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.rand(100),\n",
    "    'feature_2': np.random.rand(100),\n",
    "    'feature_3': np.random.rand(100),\n",
    "    'feature_4': np.random.rand(100),\n",
    "    'feature_5': np.random.rand(100),\n",
    "    'feature_6': np.random.rand(100),\n",
    "    'feature_7': np.random.rand(100),\n",
    "    'feature_8': np.random.rand(100),\n",
    "    'feature_9': np.random.rand(100),\n",
    "    'feature_10': np.random.rand(100),\n",
    "})\n",
    "\n",
    "# variable objetivo\n",
    "# la asociamos linealmente con 3 de las 5 caracteristicas\n",
    "y = (\n",
    "    3*X['feature_2'] + \n",
    "    2*X['feature_5'] + \n",
    "    X['feature_1'] + \n",
    "    X['feature_7']*X['feature_7'] + \n",
    "    X['feature_9']*X['feature_9']*X['feature_9'] +\n",
    "    np.random.rand(100)\n",
    ")\n",
    "y.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
