{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __KerasTuner para la construccion del mejor modelo__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 09:30:40.639398: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-08 09:30:41.557478: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-08 09:30:42.352064: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731076242.800737    6334 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731076242.876896    6334 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 09:30:44.301818: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# librerias\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# libreria para trabajar con las bases de datos \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27455 images belonging to 24 classes.\n",
      "Found 1425 images belonging to 24 classes.\n",
      "Found 7172 images belonging to 24 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ruta de los archivos\n",
    "train_dir = './sign-language-img/Train'\n",
    "test_dir = './sign-language-img/Test'\n",
    "\n",
    "# data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
    "\n",
    "# generator para test, training y validation\n",
    "# para datos de entrenamiento\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (28, 28),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "# para datos de validacion\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (28, 28),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "# para datos de prueba\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (28, 28),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'grayscale'\n",
    ")\n",
    "\n",
    "# clases\n",
    "classes = [char for char in string.ascii_uppercase if char != 'J' if char != 'Z']\n",
    "\n",
    "# funcion para mostrar las imagenes\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize = (10, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img[:,:,0])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# mostrar 5 imagenes\n",
    "sample_training_images, _ = next(train_generator)\n",
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo a trabajar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con el que vamos a trabajar es el mismo con el que hemos venido trabajando. Vamos a definirlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para generalizar la creacion del modelo\n",
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(75, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, kernel_regularizer = regularizers.l2(1e-5), activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer = regularizers.l2(1e-5), activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(len(classes), activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando Autotuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargar la libreria kerastuner y keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6334/2517507747.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta ocasión crearemos un nuevo constructor de modelos, este recibirá como parámetros un objeto tuner que determinará las variaciones de diferentes hiperparámetros.\n",
    "\n",
    "- Arquitectura general, donde agregaremos una capa de convolución, Max Pooling y aplanamiento de manera fija\n",
    "\n",
    "- Primer variable del constructor: La cantidad de neuronas en la siguiente capa oculta, se inicializará en 16 e incrementará hasta 32 dando saltos de 8 en 8.\n",
    "\n",
    "- La capa oculta sera de 32 neuronas.\n",
    "\n",
    "- La cantidad de neuronas de la siguiente capa será el objeto iterador. El resto de la red se mantendrá estable.\n",
    "\n",
    "- Variaciones en el learning rate, donde empezaremos el modelo con 3 posibles learning rate: 0.01, 0.001 y 0.0001.\n",
    "\n",
    "- Al momento de compilar el modelo definiremos Adam como optimizador, sin embargo, llamaremos directamente a la clase y le entregaremos el objeto iterador. El resto de parámetros seguirán iguales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructor_modelos(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(75, (3,3), activation='relu', input_shape = (28,28,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=8, max_value=32, step=8)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units, activation='relu', kernel_regularizer=regularizers.l2(1e-5)))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-5)))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(len(classes), activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=hp_learning_rate), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función será la materia prima del tuner, el cual hará pruebas con todas las combinatorias para encontrar el modelo más optimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando la mejor configuracion para tu modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el generador de modelos definido podremos crear el tuner que iterará a través de la configuración expuesta.\n",
    "\n",
    "Crearemos una instancia Hyperband (que será el objeto que iterará en las configuraciones). Sus parametros seran:\n",
    "\n",
    "- Función generador\n",
    "- Métrica objetivo (en este caso será val_accuracy para medir la precisión real del modelo)\n",
    "- Máximo de 5 épocas\n",
    "- factor de 2\n",
    "- directorio de carga\n",
    "- nombre de proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./tuner_project/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 09:31:45.920579: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    constructor_modelos,\n",
    "    objective = 'val_accuracy',\n",
    "    max_epochs = 5,\n",
    "    factor = 2,\n",
    "    directory = './',\n",
    "    project_name = 'tuner_project'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con en tuner generado, podremos empezar nuestra búsqueda. Entregamos al método:\n",
    "- el dataset\n",
    "- las épocas máximas\n",
    "- los datos de validación\n",
    "\n",
    "Empezamos el entrenamiento y esperamos a que se complete. Guardaremos el mejor desempeño en la variable best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    train_generator, \n",
    "    epochs=10, \n",
    "    validation_data= validation_generator\n",
    "    )\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las mejores configuraciones haremos uso del método get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# numero de neuronas optimas\n",
    "print(best_hps.get('units'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# tasa de aprendizaje optimo\n",
    "print(best_hps.get('learning_rate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El mejor modelo posee 24 neuronas y una taza de aprendizaje de 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando un modelo a partir de la mejor configuracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los mejores hiperparámetros encontrados podremos construir un modelo optimizado, esto lo haremos con el método hypermodel.build de tuner que recibirá la configuración como argumento.\n",
    "\n",
    "Ahora tenemos un modelo listo para ser entrenado, agregaremos el callback de early stopping para evitar sobre entrenamientos innecesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbernal/anaconda3/envs/tf_cpu/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/jbernal/anaconda3/envs/tf_cpu/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 415ms/step - accuracy: 0.0998 - loss: 2.9445 - val_accuracy: 0.4056 - val_loss: 1.8174\n",
      "Epoch 2/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 156ms/step - accuracy: 0.3526 - loss: 1.8841 - val_accuracy: 0.4898 - val_loss: 1.5497\n",
      "Epoch 3/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - accuracy: 0.4610 - loss: 1.6039 - val_accuracy: 0.5074 - val_loss: 1.5015\n",
      "Epoch 4/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 239ms/step - accuracy: 0.5121 - loss: 1.4517 - val_accuracy: 0.5474 - val_loss: 1.4773\n",
      "Epoch 5/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 298ms/step - accuracy: 0.5442 - loss: 1.3706 - val_accuracy: 0.5298 - val_loss: 1.4433\n",
      "Epoch 6/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 259ms/step - accuracy: 0.5651 - loss: 1.3022 - val_accuracy: 0.5018 - val_loss: 1.5743\n",
      "Epoch 7/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 225ms/step - accuracy: 0.5770 - loss: 1.2643 - val_accuracy: 0.5221 - val_loss: 1.5422\n",
      "Epoch 8/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - accuracy: 0.5890 - loss: 1.2339 - val_accuracy: 0.5235 - val_loss: 1.6101\n",
      "Epoch 9/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 149ms/step - accuracy: 0.6018 - loss: 1.1852 - val_accuracy: 0.4982 - val_loss: 1.6650\n",
      "Epoch 10/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 135ms/step - accuracy: 0.6032 - loss: 1.1972 - val_accuracy: 0.4989 - val_loss: 1.6337\n",
      "Epoch 11/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 158ms/step - accuracy: 0.6110 - loss: 1.1658 - val_accuracy: 0.4989 - val_loss: 1.7571\n",
      "Epoch 12/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.6212 - loss: 1.1453 - val_accuracy: 0.5340 - val_loss: 1.6996\n",
      "Epoch 13/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 150ms/step - accuracy: 0.6244 - loss: 1.1360 - val_accuracy: 0.5382 - val_loss: 1.7314\n",
      "Epoch 14/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 129ms/step - accuracy: 0.6363 - loss: 1.0961 - val_accuracy: 0.5319 - val_loss: 1.8592\n",
      "Epoch 15/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 141ms/step - accuracy: 0.6302 - loss: 1.1254 - val_accuracy: 0.5502 - val_loss: 1.6604\n",
      "Epoch 16/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.6421 - loss: 1.0907 - val_accuracy: 0.5312 - val_loss: 1.8606\n",
      "Epoch 17/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 131ms/step - accuracy: 0.6564 - loss: 1.0561 - val_accuracy: 0.5509 - val_loss: 1.7622\n",
      "Epoch 18/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 151ms/step - accuracy: 0.6434 - loss: 1.0747 - val_accuracy: 0.5305 - val_loss: 1.8144\n",
      "Epoch 19/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 174ms/step - accuracy: 0.6474 - loss: 1.0766 - val_accuracy: 0.5011 - val_loss: 1.7999\n",
      "Epoch 20/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 129ms/step - accuracy: 0.6514 - loss: 1.0528 - val_accuracy: 0.4926 - val_loss: 1.8879\n"
     ]
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history_hypermodel = hypermodel.fit(\n",
    "    train_generator,\n",
    "    epochs = 20,\n",
    "    callbacks = [callback_early],\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El early sttoping detecto que no estaba mejorando el modelo en cada epoca por lo que detuvo el entrenamiento en la epoca 12.\n",
    "\n",
    "> El modelo alcanza un valor 0.0424 en accuracy de entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Almacenamiento y carga del Modelo__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando y descargando arquitecturas sin pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes usar la arquitectura de un modelo para basarte a la hora de entrenar otros modelos, esto no traerá los pesos, por lo que no será útil para realizar predicciones\n",
    "\n",
    "Con el método get_config de tus modelos puedes adquirir un JSON completo con la información de la arquitectura de tu red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 28, 28, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 75, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 28, 28, 1)}}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 75)}}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 24, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 1e-05}, 'registered_name': None}, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 12675)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 1e-05}, 'registered_name': None}, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 24)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 24, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 32)}}], 'build_input_shape': (None, 28, 28, 1)}\n"
     ]
    }
   ],
   "source": [
    "config_dict = hypermodel.get_config()\n",
    "print(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar un modelo con base en esta configuración bastará con usar el método from_config de los modelos secuenciales de Keras enviando como parámetro el JSON de configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_same_config = tf.keras.Sequential.from_config(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que sea la arquitectura del mismo modelo, vemos el summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12675</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">304,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">792</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │           \u001b[38;5;34m750\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12675\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │       \u001b[38;5;34m304,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m792\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,566</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m306,566\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,566</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m306,566\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_same_config.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargando arquitecturas con pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar arquitecturas con pesos es necesario usar el callback de ModelCheckpoint que nos permitirá guardar en disco el modelo con sus pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo vacio que guardaremos despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12675</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,245,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,096</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │           \u001b[38;5;34m750\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12675\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m3,245,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m3,096\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,281,798</span> (12.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,281,798\u001b[0m (12.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,281,798</span> (12.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,281,798\u001b[0m (12.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weight = get_model()\n",
    "# summary para verificar el modelo que acabamos de crear\n",
    "model_weight.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos la configuración para nuestro callback. Definimos el path donde se guardará el modelo, cada cuando se guardará, si solo guardará los pesos y el output de texto a recibir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './model_checkpoint/checkpoint.weights.h5'\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_freq = 'epoch',\n",
    "    save_weights_only = True,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenaremos el modelo sin olvidar agregar el callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.2901 - loss: 2.4099\n",
      "Epoch 1: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 309ms/step - accuracy: 0.2912 - loss: 2.4062 - val_accuracy: 0.7411 - val_loss: 0.7899\n",
      "Epoch 2/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.8612 - loss: 0.4523\n",
      "Epoch 2: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 228ms/step - accuracy: 0.8613 - loss: 0.4518 - val_accuracy: 0.8239 - val_loss: 0.5957\n",
      "Epoch 3/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9613 - loss: 0.1575\n",
      "Epoch 3: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 228ms/step - accuracy: 0.9613 - loss: 0.1574 - val_accuracy: 0.8372 - val_loss: 0.5971\n",
      "Epoch 4/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9828 - loss: 0.0888\n",
      "Epoch 4: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 225ms/step - accuracy: 0.9828 - loss: 0.0888 - val_accuracy: 0.8477 - val_loss: 0.5642\n",
      "Epoch 5/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9898 - loss: 0.0639\n",
      "Epoch 5: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 214ms/step - accuracy: 0.9898 - loss: 0.0639 - val_accuracy: 0.8344 - val_loss: 0.6012\n",
      "Epoch 6/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9935 - loss: 0.0527\n",
      "Epoch 6: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 272ms/step - accuracy: 0.9935 - loss: 0.0527 - val_accuracy: 0.8589 - val_loss: 0.6150\n",
      "Epoch 7/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9957 - loss: 0.0432\n",
      "Epoch 7: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 270ms/step - accuracy: 0.9957 - loss: 0.0432 - val_accuracy: 0.8589 - val_loss: 0.6715\n",
      "Epoch 8/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9965 - loss: 0.0387\n",
      "Epoch 8: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 236ms/step - accuracy: 0.9965 - loss: 0.0387 - val_accuracy: 0.8512 - val_loss: 0.7168\n",
      "Epoch 9/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9953 - loss: 0.0420\n",
      "Epoch 9: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 231ms/step - accuracy: 0.9953 - loss: 0.0420 - val_accuracy: 0.8512 - val_loss: 0.6623\n",
      "Epoch 10/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9967 - loss: 0.0368\n",
      "Epoch 10: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 245ms/step - accuracy: 0.9967 - loss: 0.0368 - val_accuracy: 0.8554 - val_loss: 0.6996\n",
      "Epoch 11/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9968 - loss: 0.0351\n",
      "Epoch 11: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 248ms/step - accuracy: 0.9968 - loss: 0.0351 - val_accuracy: 0.8596 - val_loss: 0.6782\n",
      "Epoch 12/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9972 - loss: 0.0341\n",
      "Epoch 12: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 279ms/step - accuracy: 0.9972 - loss: 0.0341 - val_accuracy: 0.8519 - val_loss: 0.7681\n",
      "Epoch 13/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9981 - loss: 0.0311\n",
      "Epoch 13: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 249ms/step - accuracy: 0.9981 - loss: 0.0311 - val_accuracy: 0.8526 - val_loss: 0.7082\n",
      "Epoch 14/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9969 - loss: 0.0341\n",
      "Epoch 14: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 231ms/step - accuracy: 0.9969 - loss: 0.0341 - val_accuracy: 0.8477 - val_loss: 0.7511\n",
      "Epoch 15/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9968 - loss: 0.0334\n",
      "Epoch 15: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 230ms/step - accuracy: 0.9968 - loss: 0.0334 - val_accuracy: 0.8611 - val_loss: 0.8156\n",
      "Epoch 16/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9978 - loss: 0.0316\n",
      "Epoch 16: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 269ms/step - accuracy: 0.9978 - loss: 0.0316 - val_accuracy: 0.8540 - val_loss: 0.8209\n",
      "Epoch 17/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.9971 - loss: 0.0335\n",
      "Epoch 17: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 317ms/step - accuracy: 0.9971 - loss: 0.0335 - val_accuracy: 0.8414 - val_loss: 0.7143\n",
      "Epoch 18/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9976 - loss: 0.0323\n",
      "Epoch 18: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 316ms/step - accuracy: 0.9976 - loss: 0.0323 - val_accuracy: 0.8547 - val_loss: 0.7374\n",
      "Epoch 19/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9970 - loss: 0.0324\n",
      "Epoch 19: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 294ms/step - accuracy: 0.9970 - loss: 0.0324 - val_accuracy: 0.8470 - val_loss: 0.8079\n",
      "Epoch 20/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9973 - loss: 0.0313\n",
      "Epoch 20: saving model to ./model_checkpoint/checkpoint.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 301ms/step - accuracy: 0.9973 - loss: 0.0313 - val_accuracy: 0.8611 - val_loss: 0.7442\n"
     ]
    }
   ],
   "source": [
    "history_weight = model_weight.fit(\n",
    "    train_generator,\n",
    "    epochs = 20,\n",
    "    callbacks = [checkpoint_weight],\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto hemos guardado un historial entero de nuestro modelo, puedes revisarlo en el directorio model_checkpoints/checkpoint.weights.h5\n",
    "\n",
    "Si deseas guardar manualmente los pesos de tu red lo puedes haces con el método save indicando el directorio de salida. Esta manera únicamente guardará la última iteración, por lo que si por alguna razón la red sufrió un daño en esta etapa, no podrás revertirlo (a comparación del callback que guarda el historial entero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_weight.save('./model_manual/my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando arquitectura con pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un nuevo modelo hueco con la misma estructura que el original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbernal/anaconda3/envs/tf_cpu/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_weight2 = get_model()\n",
    "model_weight2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar el modelo desde disco nos basta con usar el método load_weights indicando la locación a cargar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbernal/anaconda3/envs/tf_cpu/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_weight2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si evaluamos el desempeño del modelo original y el cargado nos daremos cuenta que son literalmente el mismo, reafirmando que el proceso de carga fue correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbernal/anaconda3/envs/tf_cpu/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 408ms/step - accuracy: 0.8706 - loss: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6903767585754395, 0.8655884265899658]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desempeno del modelo cargado\n",
    "model_weight2.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 0.8738 - loss: 0.6446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6903769969940186, 0.8655884265899658]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desempeno del modelo original\n",
    "model_weight.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El desempeno de ambos modelos son iguales lo que implica que la carga de los pesos se hizo correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Criterios para almacenar los modelos__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejorando el guardado de los pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definimos un path para guardar nuestro nuevo modelo.\n",
    "\n",
    "- Cambiamos la forma en como se guarda el modelo modificando ModelCheckPoint.\n",
    "\n",
    "    - Se cambia a False el parametro _save_weight_only_.\n",
    "    - Agregamos _val_accuracy_ como monitor de desempeno.\n",
    "    - Guardamos solo la mejor version del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nueva ruta\n",
    "checkpoint_path = './model_checkpoint_complete/model_checkpoint_complete.keras'\n",
    "\n",
    "# modificacion del callback\n",
    "checkpoint_weight = ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_freq = 'epoch',\n",
    "    save_weights_only = False,\n",
    "    monitor = 'val_accuracy',\n",
    "    save_best_only = True,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un modelo nuevo para comprender cómo se guardan los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbernal/anaconda3/envs/tf_cpu/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_complete = get_model()\n",
    "model_complete.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.2162 - loss: 2.6339\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71228, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 625ms/step - accuracy: 0.2172 - loss: 2.6306 - val_accuracy: 0.7123 - val_loss: 0.8870\n",
      "Epoch 2/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8052 - loss: 0.6285\n",
      "Epoch 2: val_accuracy improved from 0.71228 to 0.78456, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 248ms/step - accuracy: 0.8054 - loss: 0.6279 - val_accuracy: 0.7846 - val_loss: 0.6398\n",
      "Epoch 3/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9330 - loss: 0.2405\n",
      "Epoch 3: val_accuracy improved from 0.78456 to 0.83579, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 276ms/step - accuracy: 0.9330 - loss: 0.2404 - val_accuracy: 0.8358 - val_loss: 0.5789\n",
      "Epoch 4/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9704 - loss: 0.1289\n",
      "Epoch 4: val_accuracy improved from 0.83579 to 0.84140, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 250ms/step - accuracy: 0.9704 - loss: 0.1288 - val_accuracy: 0.8414 - val_loss: 0.6216\n",
      "Epoch 5/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9836 - loss: 0.0832\n",
      "Epoch 5: val_accuracy improved from 0.84140 to 0.85193, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 259ms/step - accuracy: 0.9836 - loss: 0.0832 - val_accuracy: 0.8519 - val_loss: 0.6041\n",
      "Epoch 6/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9878 - loss: 0.0670\n",
      "Epoch 6: val_accuracy did not improve from 0.85193\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 250ms/step - accuracy: 0.9878 - loss: 0.0670 - val_accuracy: 0.8449 - val_loss: 0.5978\n",
      "Epoch 7/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9912 - loss: 0.0570\n",
      "Epoch 7: val_accuracy improved from 0.85193 to 0.86105, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 257ms/step - accuracy: 0.9912 - loss: 0.0570 - val_accuracy: 0.8611 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9937 - loss: 0.0495\n",
      "Epoch 8: val_accuracy did not improve from 0.86105\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 257ms/step - accuracy: 0.9937 - loss: 0.0495 - val_accuracy: 0.8547 - val_loss: 0.6480\n",
      "Epoch 9/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9937 - loss: 0.0470\n",
      "Epoch 9: val_accuracy did not improve from 0.86105\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 268ms/step - accuracy: 0.9937 - loss: 0.0470 - val_accuracy: 0.8449 - val_loss: 0.7149\n",
      "Epoch 10/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9959 - loss: 0.0394\n",
      "Epoch 10: val_accuracy did not improve from 0.86105\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 301ms/step - accuracy: 0.9959 - loss: 0.0394 - val_accuracy: 0.8611 - val_loss: 0.6275\n",
      "Epoch 11/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9936 - loss: 0.0452\n",
      "Epoch 11: val_accuracy improved from 0.86105 to 0.86456, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 258ms/step - accuracy: 0.9936 - loss: 0.0452 - val_accuracy: 0.8646 - val_loss: 0.6534\n",
      "Epoch 12/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9951 - loss: 0.0403\n",
      "Epoch 12: val_accuracy did not improve from 0.86456\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 246ms/step - accuracy: 0.9951 - loss: 0.0403 - val_accuracy: 0.8589 - val_loss: 0.7335\n",
      "Epoch 13/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9957 - loss: 0.0384\n",
      "Epoch 13: val_accuracy did not improve from 0.86456\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 255ms/step - accuracy: 0.9957 - loss: 0.0384 - val_accuracy: 0.8386 - val_loss: 0.7414\n",
      "Epoch 14/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9955 - loss: 0.0393\n",
      "Epoch 14: val_accuracy improved from 0.86456 to 0.86667, saving model to ./model_checkpoint_complete.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 288ms/step - accuracy: 0.9955 - loss: 0.0393 - val_accuracy: 0.8667 - val_loss: 0.6721\n",
      "Epoch 15/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9963 - loss: 0.0361\n",
      "Epoch 15: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 265ms/step - accuracy: 0.9963 - loss: 0.0361 - val_accuracy: 0.8611 - val_loss: 0.6930\n",
      "Epoch 16/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9964 - loss: 0.0344\n",
      "Epoch 16: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 259ms/step - accuracy: 0.9964 - loss: 0.0344 - val_accuracy: 0.8646 - val_loss: 0.7463\n",
      "Epoch 17/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9956 - loss: 0.0348\n",
      "Epoch 17: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 261ms/step - accuracy: 0.9956 - loss: 0.0348 - val_accuracy: 0.8484 - val_loss: 0.7669\n",
      "Epoch 18/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9951 - loss: 0.0375\n",
      "Epoch 18: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 260ms/step - accuracy: 0.9951 - loss: 0.0375 - val_accuracy: 0.8568 - val_loss: 0.7080\n",
      "Epoch 19/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9963 - loss: 0.0352\n",
      "Epoch 19: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 254ms/step - accuracy: 0.9963 - loss: 0.0352 - val_accuracy: 0.8505 - val_loss: 0.8023\n",
      "Epoch 20/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9967 - loss: 0.0347\n",
      "Epoch 20: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 277ms/step - accuracy: 0.9967 - loss: 0.0347 - val_accuracy: 0.8526 - val_loss: 0.7210\n"
     ]
    }
   ],
   "source": [
    "history_complete = model_complete.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint_weight],\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si durante el entrenamiento la red mejora en su val_accuracy, entonces se guardará en disco, si por el contrario no detecta una mejora, entonces ignorará esa iteración.\n",
    "\n",
    "Al final obtendremos de output un directorio con varios archivos, asegúrate de guardarlos todos de manera local, dado que si falta alguno la carga del modelo fallará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar la configuracion entera manualmente, hacemos uso del metodo save de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complete.save('./save_model_complete/my_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
